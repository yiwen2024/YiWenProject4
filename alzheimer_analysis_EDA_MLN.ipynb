{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import regularizers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholConsumption</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>...</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>ADL</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Disorientation</th>\n",
       "      <th>PersonalityChanges</th>\n",
       "      <th>DifficultyCompletingTasks</th>\n",
       "      <th>Forgetfulness</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>DoctorInCharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4751</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.927749</td>\n",
       "      <td>0</td>\n",
       "      <td>13.297218</td>\n",
       "      <td>6.327112</td>\n",
       "      <td>1.347214</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.725883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4752</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.827681</td>\n",
       "      <td>0</td>\n",
       "      <td>4.542524</td>\n",
       "      <td>7.619885</td>\n",
       "      <td>0.518767</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.592424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4753</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17.795882</td>\n",
       "      <td>0</td>\n",
       "      <td>19.555085</td>\n",
       "      <td>7.844988</td>\n",
       "      <td>1.826335</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.119548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4754</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.800817</td>\n",
       "      <td>1</td>\n",
       "      <td>12.209266</td>\n",
       "      <td>8.428001</td>\n",
       "      <td>7.435604</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.481226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4755</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.716974</td>\n",
       "      <td>0</td>\n",
       "      <td>18.454356</td>\n",
       "      <td>6.310461</td>\n",
       "      <td>0.795498</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  Age  Gender  Ethnicity  EducationLevel        BMI  Smoking  \\\n",
       "0       4751   73       0          0               2  22.927749        0   \n",
       "1       4752   89       0          0               0  26.827681        0   \n",
       "2       4753   73       0          3               1  17.795882        0   \n",
       "3       4754   74       1          0               1  33.800817        1   \n",
       "4       4755   89       0          0               0  20.716974        0   \n",
       "\n",
       "   AlcoholConsumption  PhysicalActivity  DietQuality  ...  MemoryComplaints  \\\n",
       "0           13.297218          6.327112     1.347214  ...                 0   \n",
       "1            4.542524          7.619885     0.518767  ...                 0   \n",
       "2           19.555085          7.844988     1.826335  ...                 0   \n",
       "3           12.209266          8.428001     7.435604  ...                 0   \n",
       "4           18.454356          6.310461     0.795498  ...                 0   \n",
       "\n",
       "   BehavioralProblems       ADL  Confusion  Disorientation  \\\n",
       "0                   0  1.725883          0               0   \n",
       "1                   0  2.592424          0               0   \n",
       "2                   0  7.119548          0               1   \n",
       "3                   1  6.481226          0               0   \n",
       "4                   0  0.014691          0               0   \n",
       "\n",
       "   PersonalityChanges  DifficultyCompletingTasks  Forgetfulness  Diagnosis  \\\n",
       "0                   0                          1              0          0   \n",
       "1                   0                          0              1          0   \n",
       "2                   0                          1              0          0   \n",
       "3                   0                          0              0          0   \n",
       "4                   1                          1              0          0   \n",
       "\n",
       "   DoctorInCharge  \n",
       "0       XXXConfid  \n",
       "1       XXXConfid  \n",
       "2       XXXConfid  \n",
       "3       XXXConfid  \n",
       "4       XXXConfid  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame for the healthcare-dataset-stroke-data.csv. \n",
    "file_path = Path(\"Resources/alzheimers_disease_data.csv\")\n",
    "alzheimer_df = pd.read_csv(file_path)\n",
    "alzheimer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data cleaning and preparation process \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total rows: 2149\n",
      "Number of total columns: 35\n"
     ]
    }
   ],
   "source": [
    "# determine the number of rows and columns.\n",
    "alzheimer_df_rc, alzheimer_df_cc = alzheimer_df.shape\n",
    "print('Number of total rows:', alzheimer_df_rc)\n",
    "print('Number of total columns:', alzheimer_df_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PatientID', 'Age', 'Gender', 'Ethnicity', 'EducationLevel', 'BMI',\n",
       "       'Smoking', 'AlcoholConsumption', 'PhysicalActivity', 'DietQuality',\n",
       "       'SleepQuality', 'FamilyHistoryAlzheimers', 'CardiovascularDisease',\n",
       "       'Diabetes', 'Depression', 'HeadInjury', 'Hypertension', 'SystolicBP',\n",
       "       'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL', 'CholesterolHDL',\n",
       "       'CholesterolTriglycerides', 'MMSE', 'FunctionalAssessment',\n",
       "       'MemoryComplaints', 'BehavioralProblems', 'ADL', 'Confusion',\n",
       "       'Disorientation', 'PersonalityChanges', 'DifficultyCompletingTasks',\n",
       "       'Forgetfulness', 'Diagnosis', 'DoctorInCharge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all columns inside of the DataFrame\n",
    "alzheimer_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show duplicates\n",
    "duplicate = alzheimer_df[alzheimer_df.duplicated()]\n",
    "print(\"Duplicate Rows:\", len(duplicate), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatientID                    0\n",
       "Age                          0\n",
       "Gender                       0\n",
       "Ethnicity                    0\n",
       "EducationLevel               0\n",
       "BMI                          0\n",
       "Smoking                      0\n",
       "AlcoholConsumption           0\n",
       "PhysicalActivity             0\n",
       "DietQuality                  0\n",
       "SleepQuality                 0\n",
       "FamilyHistoryAlzheimers      0\n",
       "CardiovascularDisease        0\n",
       "Diabetes                     0\n",
       "Depression                   0\n",
       "HeadInjury                   0\n",
       "Hypertension                 0\n",
       "SystolicBP                   0\n",
       "DiastolicBP                  0\n",
       "CholesterolTotal             0\n",
       "CholesterolLDL               0\n",
       "CholesterolHDL               0\n",
       "CholesterolTriglycerides     0\n",
       "MMSE                         0\n",
       "FunctionalAssessment         0\n",
       "MemoryComplaints             0\n",
       "BehavioralProblems           0\n",
       "ADL                          0\n",
       "Confusion                    0\n",
       "Disorientation               0\n",
       "PersonalityChanges           0\n",
       "DifficultyCompletingTasks    0\n",
       "Forgetfulness                0\n",
       "Diagnosis                    0\n",
       "DoctorInCharge               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "alzheimer_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with missing information \n",
    "alzheimer_df = alzheimer_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatientID 2149\n",
      "Age 31\n",
      "Gender 2\n",
      "Ethnicity 4\n",
      "EducationLevel 4\n",
      "BMI 2149\n",
      "Smoking 2\n",
      "AlcoholConsumption 2149\n",
      "PhysicalActivity 2149\n",
      "DietQuality 2149\n",
      "SleepQuality 2149\n",
      "FamilyHistoryAlzheimers 2\n",
      "CardiovascularDisease 2\n",
      "Diabetes 2\n",
      "Depression 2\n",
      "HeadInjury 2\n",
      "Hypertension 2\n",
      "SystolicBP 90\n",
      "DiastolicBP 60\n",
      "CholesterolTotal 2149\n",
      "CholesterolLDL 2149\n",
      "CholesterolHDL 2149\n",
      "CholesterolTriglycerides 2149\n",
      "MMSE 2149\n",
      "FunctionalAssessment 2149\n",
      "MemoryComplaints 2\n",
      "BehavioralProblems 2\n",
      "ADL 2149\n",
      "Confusion 2\n",
      "Disorientation 2\n",
      "PersonalityChanges 2\n",
      "DifficultyCompletingTasks 2\n",
      "Forgetfulness 2\n",
      "Diagnosis 2\n",
      "DoctorInCharge 1\n"
     ]
    }
   ],
   "source": [
    "# print out columns and number of unique values\n",
    "for col in alzheimer_df.columns:\n",
    "    print(col, alzheimer_df[col].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exploratory Data Analysis (EDA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "0    1389\n",
       "1     760\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the stroke outcome value counts\n",
    "alzheimer_counts = alzheimer_df['Diagnosis'].value_counts()\n",
    "alzheimer_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>FunctionalAssessment</th>\n",
       "      <th>ADL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.463532</td>\n",
       "      <td>6.518877</td>\n",
       "      <td>1.725883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.613267</td>\n",
       "      <td>7.118696</td>\n",
       "      <td>2.592424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.356249</td>\n",
       "      <td>5.895077</td>\n",
       "      <td>7.119548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.991127</td>\n",
       "      <td>8.965106</td>\n",
       "      <td>6.481226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.517609</td>\n",
       "      <td>6.045039</td>\n",
       "      <td>0.014691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.201190</td>\n",
       "      <td>0.238667</td>\n",
       "      <td>4.492838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.458060</td>\n",
       "      <td>8.687480</td>\n",
       "      <td>9.204952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.011003</td>\n",
       "      <td>1.972137</td>\n",
       "      <td>5.036334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.030491</td>\n",
       "      <td>5.173891</td>\n",
       "      <td>3.785399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.114777</td>\n",
       "      <td>6.307543</td>\n",
       "      <td>8.327563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2149 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ethnicity  Gender  Age  EducationLevel  Diagnosis  MemoryComplaints  \\\n",
       "0             0       0   73               2          0                 0   \n",
       "1             0       0   89               0          0                 0   \n",
       "2             3       0   73               1          0                 0   \n",
       "3             0       1   74               1          0                 0   \n",
       "4             0       0   89               0          0                 0   \n",
       "...         ...     ...  ...             ...        ...               ...   \n",
       "2144          0       0   61               1          1                 0   \n",
       "2145          0       0   75               2          1                 0   \n",
       "2146          0       0   77               1          1                 0   \n",
       "2147          3       1   78               1          1                 0   \n",
       "2148          0       0   72               2          0                 0   \n",
       "\n",
       "      BehavioralProblems       MMSE  FunctionalAssessment       ADL  \n",
       "0                      0  21.463532              6.518877  1.725883  \n",
       "1                      0  20.613267              7.118696  2.592424  \n",
       "2                      0   7.356249              5.895077  7.119548  \n",
       "3                      1  13.991127              8.965106  6.481226  \n",
       "4                      0  13.517609              6.045039  0.014691  \n",
       "...                  ...        ...                   ...       ...  \n",
       "2144                   0   1.201190              0.238667  4.492838  \n",
       "2145                   1   6.458060              8.687480  9.204952  \n",
       "2146                   0  17.011003              1.972137  5.036334  \n",
       "2147                   0   4.030491              5.173891  3.785399  \n",
       "2148                   1  11.114777              6.307543  8.327563  \n",
       "\n",
       "[2149 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep part of columns for abalysis\n",
    "alzheimer_cleanML_df = alzheimer_df[['Ethnicity', 'Gender', 'Age', 'EducationLevel', 'Diagnosis', 'MemoryComplaints','BehavioralProblems', 'MMSE', 'FunctionalAssessment','ADL']]\n",
    "alzheimer_cleanML_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age: The age of the patients ranges from 60 to 90 years.\n",
    "**Gender: Gender of the patients, where 0 represents Male and 1 represents Female.\n",
    "**Ethnicity: The ethnicity of the patients, coded as follows:\n",
    "0: Caucasian\n",
    "1: African American\n",
    "2: Asian\n",
    "3: Other\n",
    "**EducationLevel: The education level of the patients, coded as follows:\n",
    "0: None\n",
    "1: High School\n",
    "2: Bachelor's\n",
    "3: Higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>FunctionalAssessment</th>\n",
       "      <th>ADL</th>\n",
       "      <th>Caucasian</th>\n",
       "      <th>African American</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Other</th>\n",
       "      <th>None</th>\n",
       "      <th>High School</th>\n",
       "      <th>Bachelor's</th>\n",
       "      <th>Higher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.463532</td>\n",
       "      <td>6.518877</td>\n",
       "      <td>1.725883</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.613267</td>\n",
       "      <td>7.118696</td>\n",
       "      <td>2.592424</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.356249</td>\n",
       "      <td>5.895077</td>\n",
       "      <td>7.119548</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.991127</td>\n",
       "      <td>8.965106</td>\n",
       "      <td>6.481226</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.517609</td>\n",
       "      <td>6.045039</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.201190</td>\n",
       "      <td>0.238667</td>\n",
       "      <td>4.492838</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.458060</td>\n",
       "      <td>8.687480</td>\n",
       "      <td>9.204952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.011003</td>\n",
       "      <td>1.972137</td>\n",
       "      <td>5.036334</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.030491</td>\n",
       "      <td>5.173891</td>\n",
       "      <td>3.785399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.114777</td>\n",
       "      <td>6.307543</td>\n",
       "      <td>8.327563</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2149 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Age  Diagnosis  MemoryComplaints  BehavioralProblems       MMSE  \\\n",
       "0          0   73          0                 0                   0  21.463532   \n",
       "1          0   89          0                 0                   0  20.613267   \n",
       "2          0   73          0                 0                   0   7.356249   \n",
       "3          1   74          0                 0                   1  13.991127   \n",
       "4          0   89          0                 0                   0  13.517609   \n",
       "...      ...  ...        ...               ...                 ...        ...   \n",
       "2144       0   61          1                 0                   0   1.201190   \n",
       "2145       0   75          1                 0                   1   6.458060   \n",
       "2146       0   77          1                 0                   0  17.011003   \n",
       "2147       1   78          1                 0                   0   4.030491   \n",
       "2148       0   72          0                 0                   1  11.114777   \n",
       "\n",
       "      FunctionalAssessment       ADL  Caucasian  African American  Asian  \\\n",
       "0                 6.518877  1.725883          1                 0      0   \n",
       "1                 7.118696  2.592424          1                 0      0   \n",
       "2                 5.895077  7.119548          0                 0      0   \n",
       "3                 8.965106  6.481226          1                 0      0   \n",
       "4                 6.045039  0.014691          1                 0      0   \n",
       "...                    ...       ...        ...               ...    ...   \n",
       "2144              0.238667  4.492838          1                 0      0   \n",
       "2145              8.687480  9.204952          1                 0      0   \n",
       "2146              1.972137  5.036334          1                 0      0   \n",
       "2147              5.173891  3.785399          0                 0      0   \n",
       "2148              6.307543  8.327563          1                 0      0   \n",
       "\n",
       "      Other  None  High School  Bachelor's  Higher  \n",
       "0         0     0            0           1       0  \n",
       "1         0     1            0           0       0  \n",
       "2         1     0            1           0       0  \n",
       "3         0     0            1           0       0  \n",
       "4         0     1            0           0       0  \n",
       "...     ...   ...          ...         ...     ...  \n",
       "2144      0     0            1           0       0  \n",
       "2145      0     0            0           1       0  \n",
       "2146      0     0            1           0       0  \n",
       "2147      1     0            1           0       0  \n",
       "2148      0     0            0           1       0  \n",
       "\n",
       "[2149 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new columns for each ethnicity and education level to obtain binary values\n",
    "alzheimer_cleanML_df['Caucasian'] = (alzheimer_cleanML_df['Ethnicity'] == 0).astype(int)\n",
    "alzheimer_cleanML_df['African American'] = (alzheimer_cleanML_df['Ethnicity'] == 1).astype(int)\n",
    "alzheimer_cleanML_df['Asian'] = (alzheimer_cleanML_df['Ethnicity'] == 2).astype(int)\n",
    "alzheimer_cleanML_df['Other'] = (alzheimer_cleanML_df['Ethnicity'] == 3).astype(int)\n",
    "\n",
    "alzheimer_cleanML_df['None'] = (alzheimer_cleanML_df['EducationLevel'] == 0).astype(int)\n",
    "alzheimer_cleanML_df['High School'] = (alzheimer_cleanML_df['EducationLevel'] == 1).astype(int)\n",
    "alzheimer_cleanML_df['Bachelor\\'s'] = (alzheimer_cleanML_df['EducationLevel'] == 2).astype(int)\n",
    "alzheimer_cleanML_df['Higher'] = (alzheimer_cleanML_df['EducationLevel'] == 3).astype(int)\n",
    "\n",
    "# Drop the original Ethnicity and EducationLevel columns\n",
    "alzheimer_cleanML_df = alzheimer_cleanML_df.drop('Ethnicity', axis=1)\n",
    "alzheimer_cleanML_df = alzheimer_cleanML_df.drop('EducationLevel', axis=1)\n",
    "\n",
    "# Display the first few rows of the reshaped dataframe\n",
    "alzheimer_cleanML_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data:\n",
    "X = alzheimer_cleanML_df.drop('Diagnosis', axis=1)  \n",
    "y = alzheimer_cleanML_df['Diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# Review number of features\n",
    "print(len(X_train_scaled[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(8, activation='sigmoid'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,777</span> (14.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,777\u001b[0m (14.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,777</span> (14.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,777\u001b[0m (14.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5061 - loss: 0.6938 - val_accuracy: 0.6192 - val_loss: 0.6447\n",
      "Epoch 2/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6377 - loss: 0.6151 - val_accuracy: 0.6831 - val_loss: 0.5548\n",
      "Epoch 3/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7894 - loss: 0.4977 - val_accuracy: 0.8110 - val_loss: 0.4561\n",
      "Epoch 4/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8595 - loss: 0.4102 - val_accuracy: 0.8140 - val_loss: 0.4292\n",
      "Epoch 5/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.3733 - val_accuracy: 0.8110 - val_loss: 0.4216\n",
      "Epoch 6/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8598 - loss: 0.3787 - val_accuracy: 0.8169 - val_loss: 0.4045\n",
      "Epoch 7/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8747 - loss: 0.3537 - val_accuracy: 0.8401 - val_loss: 0.3837\n",
      "Epoch 8/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8868 - loss: 0.3209 - val_accuracy: 0.8401 - val_loss: 0.3814\n",
      "Epoch 9/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.2966 - val_accuracy: 0.8430 - val_loss: 0.3674\n",
      "Epoch 10/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.2842 - val_accuracy: 0.8547 - val_loss: 0.3602\n",
      "Epoch 11/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9046 - loss: 0.2755 - val_accuracy: 0.8488 - val_loss: 0.3561\n",
      "Epoch 12/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2798 - val_accuracy: 0.8605 - val_loss: 0.3493\n",
      "Epoch 13/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2740 - val_accuracy: 0.8663 - val_loss: 0.3487\n",
      "Epoch 14/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.2888 - val_accuracy: 0.8663 - val_loss: 0.3439\n",
      "Epoch 15/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2699 - val_accuracy: 0.8517 - val_loss: 0.3477\n",
      "Epoch 16/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2461 - val_accuracy: 0.8488 - val_loss: 0.3525\n",
      "Epoch 17/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9227 - loss: 0.2517 - val_accuracy: 0.8488 - val_loss: 0.3525\n",
      "Epoch 18/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.2007 - val_accuracy: 0.8547 - val_loss: 0.3513\n",
      "Epoch 19/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.2439 - val_accuracy: 0.8488 - val_loss: 0.3579\n",
      "Epoch 20/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9315 - loss: 0.2214 - val_accuracy: 0.8605 - val_loss: 0.3377\n",
      "Epoch 21/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2234 - val_accuracy: 0.8634 - val_loss: 0.3475\n",
      "Epoch 22/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9373 - loss: 0.2290 - val_accuracy: 0.8517 - val_loss: 0.3459\n",
      "Epoch 23/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.2373 - val_accuracy: 0.8605 - val_loss: 0.3649\n",
      "Epoch 24/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9372 - loss: 0.2123 - val_accuracy: 0.8692 - val_loss: 0.3528\n",
      "Epoch 25/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9411 - loss: 0.2038 - val_accuracy: 0.8459 - val_loss: 0.3821\n",
      "Epoch 26/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.2064 - val_accuracy: 0.8547 - val_loss: 0.3664\n",
      "Epoch 27/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9507 - loss: 0.1941 - val_accuracy: 0.8663 - val_loss: 0.3577\n",
      "Epoch 28/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.1962 - val_accuracy: 0.8547 - val_loss: 0.3840\n",
      "Epoch 29/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9580 - loss: 0.1724 - val_accuracy: 0.8576 - val_loss: 0.3816\n",
      "Epoch 30/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9604 - loss: 0.1659 - val_accuracy: 0.8576 - val_loss: 0.3794\n",
      "Epoch 31/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9526 - loss: 0.1801 - val_accuracy: 0.8692 - val_loss: 0.3884\n",
      "Epoch 32/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9540 - loss: 0.1814 - val_accuracy: 0.8663 - val_loss: 0.3776\n",
      "Epoch 33/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.1545 - val_accuracy: 0.8547 - val_loss: 0.3965\n",
      "Epoch 34/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9651 - loss: 0.1584 - val_accuracy: 0.8721 - val_loss: 0.3780\n",
      "Epoch 35/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9564 - loss: 0.1694 - val_accuracy: 0.8517 - val_loss: 0.3877\n",
      "Epoch 36/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9623 - loss: 0.1481 - val_accuracy: 0.8605 - val_loss: 0.3966\n",
      "Epoch 37/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.1722 - val_accuracy: 0.8576 - val_loss: 0.4034\n",
      "Epoch 38/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.1571 - val_accuracy: 0.8605 - val_loss: 0.4065\n",
      "Epoch 39/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9537 - loss: 0.1715 - val_accuracy: 0.8517 - val_loss: 0.4045\n",
      "Epoch 40/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9659 - loss: 0.1499 - val_accuracy: 0.8547 - val_loss: 0.4176\n",
      "Epoch 41/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9651 - loss: 0.1556 - val_accuracy: 0.8401 - val_loss: 0.4228\n",
      "Epoch 42/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.1261 - val_accuracy: 0.8576 - val_loss: 0.4108\n",
      "Epoch 43/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9629 - loss: 0.1449 - val_accuracy: 0.8605 - val_loss: 0.4185\n",
      "Epoch 44/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.1316 - val_accuracy: 0.8547 - val_loss: 0.4339\n",
      "Epoch 45/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.1342 - val_accuracy: 0.8547 - val_loss: 0.4429\n",
      "Epoch 46/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9655 - loss: 0.1432 - val_accuracy: 0.8547 - val_loss: 0.4251\n",
      "Epoch 47/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9642 - loss: 0.1445 - val_accuracy: 0.8488 - val_loss: 0.4443\n",
      "Epoch 48/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9706 - loss: 0.1390 - val_accuracy: 0.8750 - val_loss: 0.4150\n",
      "Epoch 49/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9727 - loss: 0.1235 - val_accuracy: 0.8517 - val_loss: 0.4479\n",
      "Epoch 50/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9654 - loss: 0.1412 - val_accuracy: 0.8517 - val_loss: 0.4292\n",
      "Epoch 51/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.1215 - val_accuracy: 0.8517 - val_loss: 0.4435\n",
      "Epoch 52/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9758 - loss: 0.1160 - val_accuracy: 0.8488 - val_loss: 0.4500\n",
      "Epoch 53/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.1341 - val_accuracy: 0.8488 - val_loss: 0.4488\n",
      "Epoch 54/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.1296 - val_accuracy: 0.8488 - val_loss: 0.4586\n",
      "Epoch 55/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.1322 - val_accuracy: 0.8634 - val_loss: 0.4372\n",
      "Epoch 56/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9776 - loss: 0.1097 - val_accuracy: 0.8576 - val_loss: 0.4500\n",
      "Epoch 57/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9657 - loss: 0.1407 - val_accuracy: 0.8459 - val_loss: 0.4470\n",
      "Epoch 58/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.1315 - val_accuracy: 0.8576 - val_loss: 0.4489\n",
      "Epoch 59/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9669 - loss: 0.1507 - val_accuracy: 0.8576 - val_loss: 0.4448\n",
      "Epoch 60/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.1004 - val_accuracy: 0.8517 - val_loss: 0.4521\n",
      "Epoch 61/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.1262 - val_accuracy: 0.8547 - val_loss: 0.4605\n",
      "Epoch 62/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9651 - loss: 0.1524 - val_accuracy: 0.8576 - val_loss: 0.4523\n",
      "Epoch 63/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 0.1049 - val_accuracy: 0.8517 - val_loss: 0.4570\n",
      "Epoch 64/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9771 - loss: 0.1095 - val_accuracy: 0.8517 - val_loss: 0.4449\n",
      "Epoch 65/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.1258 - val_accuracy: 0.8517 - val_loss: 0.4397\n",
      "Epoch 66/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9778 - loss: 0.1091 - val_accuracy: 0.8459 - val_loss: 0.4749\n",
      "Epoch 67/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9772 - loss: 0.1045 - val_accuracy: 0.8488 - val_loss: 0.4798\n",
      "Epoch 68/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.1138 - val_accuracy: 0.8692 - val_loss: 0.4369\n",
      "Epoch 69/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.1142 - val_accuracy: 0.8634 - val_loss: 0.4466\n",
      "Epoch 70/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.1042 - val_accuracy: 0.8547 - val_loss: 0.4597\n",
      "Epoch 71/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 0.1399 - val_accuracy: 0.8605 - val_loss: 0.4339\n",
      "Epoch 72/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9739 - loss: 0.1191 - val_accuracy: 0.8459 - val_loss: 0.4786\n",
      "Epoch 73/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.1347 - val_accuracy: 0.8605 - val_loss: 0.4551\n",
      "Epoch 74/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.1078 - val_accuracy: 0.8547 - val_loss: 0.4391\n",
      "Epoch 75/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9727 - loss: 0.1307 - val_accuracy: 0.8605 - val_loss: 0.4502\n",
      "Epoch 76/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.1126 - val_accuracy: 0.8547 - val_loss: 0.4502\n",
      "Epoch 77/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9730 - loss: 0.1261 - val_accuracy: 0.8634 - val_loss: 0.4687\n",
      "Epoch 78/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9796 - loss: 0.1024 - val_accuracy: 0.8605 - val_loss: 0.4456\n",
      "Epoch 79/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9736 - loss: 0.1235 - val_accuracy: 0.8459 - val_loss: 0.4794\n",
      "Epoch 80/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.1065 - val_accuracy: 0.8692 - val_loss: 0.4491\n",
      "Epoch 81/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0981 - val_accuracy: 0.8605 - val_loss: 0.4582\n",
      "Epoch 82/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9761 - loss: 0.1163 - val_accuracy: 0.8663 - val_loss: 0.4597\n",
      "Epoch 83/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.1055 - val_accuracy: 0.8576 - val_loss: 0.4699\n",
      "Epoch 84/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9776 - loss: 0.1110 - val_accuracy: 0.8605 - val_loss: 0.4623\n",
      "Epoch 85/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9725 - loss: 0.1314 - val_accuracy: 0.8605 - val_loss: 0.4469\n",
      "Epoch 86/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.1276 - val_accuracy: 0.8634 - val_loss: 0.4544\n",
      "Epoch 87/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0998 - val_accuracy: 0.8605 - val_loss: 0.4795\n",
      "Epoch 88/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9730 - loss: 0.1247 - val_accuracy: 0.8576 - val_loss: 0.4842\n",
      "Epoch 89/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9776 - loss: 0.1106 - val_accuracy: 0.8692 - val_loss: 0.4766\n",
      "Epoch 90/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9742 - loss: 0.1177 - val_accuracy: 0.8605 - val_loss: 0.4562\n",
      "Epoch 91/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.0968 - val_accuracy: 0.8605 - val_loss: 0.4673\n",
      "Epoch 92/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9742 - loss: 0.1208 - val_accuracy: 0.8488 - val_loss: 0.5084\n",
      "Epoch 93/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.1059 - val_accuracy: 0.8634 - val_loss: 0.4667\n",
      "Epoch 94/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0887 - val_accuracy: 0.8517 - val_loss: 0.4876\n",
      "Epoch 95/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.1223 - val_accuracy: 0.8605 - val_loss: 0.5014\n",
      "Epoch 96/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.0872 - val_accuracy: 0.8634 - val_loss: 0.4788\n",
      "Epoch 97/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.1285 - val_accuracy: 0.8576 - val_loss: 0.4873\n",
      "Epoch 98/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.1352 - val_accuracy: 0.8547 - val_loss: 0.4514\n",
      "Epoch 99/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9735 - loss: 0.1089 - val_accuracy: 0.8488 - val_loss: 0.4610\n",
      "Epoch 100/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9675 - loss: 0.1385 - val_accuracy: 0.8576 - val_loss: 0.4850\n",
      "Epoch 101/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.1122 - val_accuracy: 0.8663 - val_loss: 0.4585\n",
      "Epoch 102/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0782 - val_accuracy: 0.8488 - val_loss: 0.4993\n",
      "Epoch 103/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0840 - val_accuracy: 0.8517 - val_loss: 0.4991\n",
      "Epoch 104/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.1148 - val_accuracy: 0.8547 - val_loss: 0.4864\n",
      "Epoch 105/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.1008 - val_accuracy: 0.8517 - val_loss: 0.4981\n",
      "Epoch 106/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.1038 - val_accuracy: 0.8488 - val_loss: 0.4933\n",
      "Epoch 107/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0916 - val_accuracy: 0.8547 - val_loss: 0.4832\n",
      "Epoch 108/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.0831 - val_accuracy: 0.8547 - val_loss: 0.5007\n",
      "Epoch 109/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.1004 - val_accuracy: 0.8517 - val_loss: 0.4935\n",
      "Epoch 110/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.1321 - val_accuracy: 0.8605 - val_loss: 0.4883\n",
      "Epoch 111/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.1122 - val_accuracy: 0.8547 - val_loss: 0.4907\n",
      "Epoch 112/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9734 - loss: 0.1239 - val_accuracy: 0.8547 - val_loss: 0.4905\n",
      "Epoch 113/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9764 - loss: 0.1123 - val_accuracy: 0.8547 - val_loss: 0.4909\n",
      "Epoch 114/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9796 - loss: 0.1009 - val_accuracy: 0.8547 - val_loss: 0.4893\n",
      "Epoch 115/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.1135 - val_accuracy: 0.8547 - val_loss: 0.4932\n",
      "Epoch 116/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9789 - loss: 0.1035 - val_accuracy: 0.8547 - val_loss: 0.4910\n",
      "Epoch 117/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9774 - loss: 0.1084 - val_accuracy: 0.8547 - val_loss: 0.4950\n",
      "Epoch 118/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9726 - loss: 0.1268 - val_accuracy: 0.8547 - val_loss: 0.4949\n",
      "Epoch 119/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9770 - loss: 0.1101 - val_accuracy: 0.8576 - val_loss: 0.4914\n",
      "Epoch 120/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9754 - loss: 0.1160 - val_accuracy: 0.8547 - val_loss: 0.4938\n",
      "Epoch 121/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.1125 - val_accuracy: 0.8547 - val_loss: 0.4928\n",
      "Epoch 122/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9785 - loss: 0.1047 - val_accuracy: 0.8576 - val_loss: 0.4953\n",
      "Epoch 123/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9737 - loss: 0.1235 - val_accuracy: 0.8547 - val_loss: 0.4968\n",
      "Epoch 124/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9759 - loss: 0.1150 - val_accuracy: 0.8547 - val_loss: 0.4962\n",
      "Epoch 125/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.1167 - val_accuracy: 0.8576 - val_loss: 0.4931\n",
      "Epoch 126/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.1115 - val_accuracy: 0.8547 - val_loss: 0.4953\n",
      "Epoch 127/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.1175 - val_accuracy: 0.8576 - val_loss: 0.4938\n",
      "Epoch 128/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9800 - loss: 0.0984 - val_accuracy: 0.8547 - val_loss: 0.4960\n",
      "Epoch 129/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0883 - val_accuracy: 0.8547 - val_loss: 0.4975\n",
      "Epoch 130/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9774 - loss: 0.1085 - val_accuracy: 0.8576 - val_loss: 0.4941\n",
      "Epoch 131/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.1243 - val_accuracy: 0.8576 - val_loss: 0.4992\n",
      "Epoch 132/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9734 - loss: 0.1238 - val_accuracy: 0.8576 - val_loss: 0.4944\n",
      "Epoch 133/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9774 - loss: 0.1090 - val_accuracy: 0.8576 - val_loss: 0.4990\n",
      "Epoch 134/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0970 - val_accuracy: 0.8576 - val_loss: 0.4977\n",
      "Epoch 135/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9742 - loss: 0.1202 - val_accuracy: 0.8576 - val_loss: 0.4977\n",
      "Epoch 136/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9782 - loss: 0.1060 - val_accuracy: 0.8576 - val_loss: 0.4980\n",
      "Epoch 137/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9776 - loss: 0.1075 - val_accuracy: 0.8576 - val_loss: 0.4978\n",
      "Epoch 138/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9808 - loss: 0.0953 - val_accuracy: 0.8576 - val_loss: 0.4982\n",
      "Epoch 139/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9776 - loss: 0.1074 - val_accuracy: 0.8576 - val_loss: 0.4973\n",
      "Epoch 140/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.1314 - val_accuracy: 0.8576 - val_loss: 0.4973\n",
      "Epoch 141/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.1124 - val_accuracy: 0.8605 - val_loss: 0.4966\n",
      "Epoch 142/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9785 - loss: 0.1045 - val_accuracy: 0.8634 - val_loss: 0.4950\n",
      "Epoch 143/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0871 - val_accuracy: 0.8576 - val_loss: 0.5028\n",
      "Epoch 144/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.1028 - val_accuracy: 0.8576 - val_loss: 0.4992\n",
      "Epoch 145/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9709 - loss: 0.1333 - val_accuracy: 0.8576 - val_loss: 0.4988\n",
      "Epoch 146/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.1007 - val_accuracy: 0.8576 - val_loss: 0.5015\n",
      "Epoch 147/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.1083 - val_accuracy: 0.8576 - val_loss: 0.4976\n",
      "Epoch 148/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9796 - loss: 0.1003 - val_accuracy: 0.8576 - val_loss: 0.5025\n",
      "Epoch 149/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9725 - loss: 0.1290 - val_accuracy: 0.8634 - val_loss: 0.4963\n",
      "Epoch 150/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9781 - loss: 0.1057 - val_accuracy: 0.8576 - val_loss: 0.5007\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=150, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8701 - loss: 0.4657 \n",
      "Test accuracy: 0.8651162981987\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "filename = 'alzheimer_ML.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAHUCAYAAADY9fvpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABuNklEQVR4nO3deViUVf8G8HtmGIZFFgXZEVBRQFzBDZdSE9NyqUzTwr0ycyF8fdXUUrNM+6W4l6WS5sJrLllZilouuYbgEq65oCwiKA6LDAPz/P6YGJsGZAYGZoD7c11cV3PmzDPn+TLp7ZnznEckCIIAIiIiIqJaSmzqARARERERVSUGXiIiIiKq1Rh4iYiIiKhWY+AlIiIiolqNgZeIiIiIajUGXiIiIiKq1Rh4iYiIiKhWY+AlIiIiolqNgZeIiIiIajUGXiKqM2JiYiASiSASifDbb7/pPC8IApo2bQqRSIRnn33WqO8tEokwd+5cg19369YtiEQixMTE6P2aCxcuQCQSQSqVIi0tzeD3JCKqbRh4iajOsbOzw7p163TaDx8+jL/++gt2dnYmGJXxfP311wCAoqIibNy40cSjISIyPQZeIqpzhg4dih07dkAul2u1r1u3Dp07d0ajRo1MNLLKUygU2Lx5M1q3bg1PT0+sX7/e1EMq0+PHjyEIgqmHQUR1AAMvEdU5w4YNAwBs3bpV0/bo0SPs2LEDY8aMKfU1Dx48wIQJE+Dp6QlLS0s0btwYs2bNgkKh0Oonl8vx5ptvwsnJCfXq1cPzzz+Pq1evlnrMa9euYfjw4XBxcYFMJkNgYCBWrVpVqXPbvXs3srKyMG7cOIwcORJXr17FsWPHdPopFArMnz8fgYGBsLKygpOTE3r06IHjx49r+qhUKqxYsQJt2rSBtbU1HB0d0alTJ+zZs0fTp6ylGr6+vhg1apTmcclykv3792PMmDFo2LAhbGxsoFAocP36dYwePRr+/v6wsbGBp6cn+vfvjwsXLugcNzs7G1OnTkXjxo0hk8ng4uKCfv364fLlyxAEAf7+/ujTp4/O63Jzc+Hg4IB3333XwIoSUW3AwEtEdY69vT0GDx6sNfu5detWiMViDB06VKd/QUEBevTogY0bNyIqKgo//fQT3njjDSxevBgvv/yypp8gCBg0aBA2bdqEqVOnYteuXejUqRP69u2rc8ykpCS0b98eFy9exOeff44ff/wRL7zwAiZPnox58+ZV+NzWrVsHmUyG119/HWPGjIFIJNJZvlFUVIS+ffvio48+wosvvohdu3YhJiYGYWFhSE5O1vQbNWoUpkyZgvbt2yM2Nhbbtm3DgAEDcOvWrQqPb8yYMZBKpdi0aRO+++47SKVSpKamwsnJCZ9++il++eUXrFq1ChYWFujYsSOuXLmieW1OTg66du2KL7/8EqNHj8YPP/yAL774As2aNUNaWhpEIhEmTZqEuLg4XLt2Tet9N27cCLlczsBLVFcJRER1xIYNGwQAwpkzZ4Rff/1VACBcvHhREARBaN++vTBq1ChBEAShRYsWwjPPPKN53RdffCEAEP73v/9pHW/RokUCAGH//v2CIAjCzz//LAAQli1bptXv448/FgAIH374oaatT58+gpeXl/Do0SOtvhMnThSsrKyEBw8eCIIgCDdv3hQACBs2bCj3/G7duiWIxWLhtdde07Q988wzgq2trSCXyzVtGzduFAAIX331VZnHOnLkiABAmDVr1lPf89/nVcLHx0cYOXKk5nFJ7UeMGFHueRQVFQmFhYWCv7+/8N5772na58+fLwAQ4uLiynytXC4X7OzshClTpmi1BwUFCT169Cj3vYmoduIMLxHVSc888wyaNGmC9evX48KFCzhz5kyZyxkOHToEW1tbDB48WKu95Cv7gwcPAgB+/fVXAMDrr7+u1W/48OFajwsKCnDw4EG89NJLsLGxQVFRkeanX79+KCgowMmTJw0+pw0bNkClUmmdx5gxY5CXl4fY2FhN288//wwrK6syz7ekDwCjz4i+8sorOm1FRUX45JNPEBQUBEtLS1hYWMDS0hLXrl3DpUuXtMbUrFkzPPfcc2Ue387ODqNHj0ZMTAzy8vIAqH9/SUlJmDhxolHPhYhqDgZeIqqTRCIRRo8ejW+//VbztXi3bt1K7ZuVlQU3NzeIRCKtdhcXF1hYWCArK0vTz8LCAk5OTlr93NzcdI5XVFSEFStWQCqVav3069cPAJCZmWnQ+ahUKsTExMDDwwMhISHIzs5GdnY2nnvuOdja2mota7h//z48PDwgFpf9V8D9+/chkUh0xl5Z7u7uOm1RUVGYM2cOBg0ahB9++AGnTp3CmTNn0Lp1azx+/FhrTF5eXuW+x6RJk5CTk4PNmzcDAFauXAkvLy8MHDjQeCdCRDWKhakHQERkKqNGjcIHH3yAL774Ah9//HGZ/ZycnHDq1CkIgqAVejMyMlBUVARnZ2dNv6KiImRlZWmF3vT0dK3j1a9fHxKJBBEREWXOoPr5+Rl0LgcOHMDt27c14/i3kydPIikpCUFBQWjYsCGOHTsGlUpVZuht2LAhiouLkZ6eXmpILSGTyXQu3AOg+UfAv/37Hw0A8O2332LEiBH45JNPtNozMzPh6OioNaa7d++WOZYSTZs2Rd++fbFq1Sr07dsXe/bswbx58yCRSMp9LRHVTpzhJaI6y9PTE9OmTUP//v0xcuTIMvv16tULubm52L17t1Z7yR63vXr1AgD06NEDADQziyW2bNmi9djGxgY9evRAQkICWrVqhdDQUJ2f0kLr06xbtw5isRi7d+/Gr7/+qvWzadMmANBcpNe3b18UFBQ89WYWJRfarVmz5qnv6+vri/Pnz2u1HTp0CLm5uXqPXSQSQSaTabX99NNPSElJ0RnT1atXcejQoXKPOWXKFJw/fx4jR46ERCLBm2++qfd4iKj24QwvEdVpn376abl9RowYgVWrVmHkyJG4desWWrZsiWPHjuGTTz5Bv379NGtKw8PD0b17d/z3v/9FXl4eQkND8fvvv2sC5z8tW7YMXbt2Rbdu3fDOO+/A19cXOTk5uH79On744Qe9Ql2JrKwsfP/99+jTp0+ZX9svXboUGzduxMKFCzFs2DBs2LAB48ePx5UrV9CjRw+oVCqcOnUKgYGBeO2119CtWzdERERgwYIFuHfvHl588UXIZDIkJCTAxsYGkyZNAgBERERgzpw5+OCDD/DMM88gKSkJK1euhIODg97jf/HFFxETE4OAgAC0atUK8fHx+Oyzz3SWL0RGRiI2NhYDBw7EjBkz0KFDBzx+/BiHDx/Giy++qPkHBwD07t0bQUFB+PXXX/HGG2/AxcVF7/EQUS1k6qvmiIiqyz93aXiaf+/SIAiCkJWVJYwfP15wd3cXLCwsBB8fH2HmzJlCQUGBVr/s7GxhzJgxgqOjo2BjYyP07t1buHz5cqm7Gdy8eVMYM2aM4OnpKUilUqFhw4ZCWFiYsGDBAq0+KGeXhujoaAGAsHv37jL7lOw0sWPHDkEQBOHx48fCBx98IPj7+wuWlpaCk5OT0LNnT+H48eOa1xQXFwtLly4VgoODBUtLS8HBwUHo3Lmz8MMPP2j6KBQK4b///a/g7e0tWFtbC88884yQmJhY5i4NpdX+4cOHwtixYwUXFxfBxsZG6Nq1q3D06FHhmWee0fk9PHz4UJgyZYrQqFEjQSqVCi4uLsILL7wgXL58Wee4c+fOFQAIJ0+eLLMuRFQ3iASBt7khIqLaJzQ0FCKRCGfOnDH1UIjIxLikgYiIag25XI6LFy/ixx9/RHx8PHbt2mXqIRGRGWDgJSKiWuPs2bPo0aMHnJyc8OGHH2LQoEGmHhIRmQEuaSAiIiKiWo3bkhERERFRrcbAS0RERES1GgMvEREREdVqvGitFCqVCqmpqbCzsyv1NphEREREZFqCICAnJwceHh5l3ia9BANvKVJTU+Ht7W3qYRARERFROe7cuaNzZ8Z/Y+AthZ2dHQB1Ae3t7avkPZRKJfbv34/w8HBIpdIqeY/agrUyDOtlGNZLf6yVYVgvw7Be+mOt1ORyOby9vTW57WkYeEtRsozB3t6+SgOvjY0N7O3t6/SHVR+slWFYL8OwXvpjrQzDehmG9dIfa6VNn+WnvGiNiIiIiGo1Bl4iIiIiqtUYeImIiIioVuMa3goSBAFFRUUoLi6u0OuVSiUsLCxQUFBQ4WPUFcaslUQigYWFBbebIyIiqkMYeCugsLAQaWlpyM/Pr/AxBEGAm5sb7ty5w/BVDmPXysbGBu7u7rC0tDTC6IiIiMjcMfAaSKVS4ebNm5BIJPDw8IClpWWFQphKpUJubi7q1atX7mbJdZ2xaiUIAgoLC3H//n3cvHkT/v7+rD0REVEdwMBroMLCQqhUKnh7e8PGxqbCx1GpVCgsLISVlRVDVzmMWStra2tIpVLcvn1bc0wiIiKq3Zi0Koghtebi746IiKhu4d/8RERERFSrMfASERERUa3GwEtEREREtRoDLxERERHVagy8ZFJKpdLUQyAiIqJajtuSGYEgCHisNOwOYCqVCo8Li2FRWFSpXQOspRKD9gH+5ZdfsGDBAly8eBESiQSdO3fGsmXL0KRJEwDA3bt38Z///Af79++HQqFAYGAgVq1ahY4dOwIA9uzZg/nz5+PixYuoV68eunfvjp07dwIARCIRdu3ahUGDBmnez9HREdHR0Rg1ahRu3boFPz8/xMbGYvXq1Th58iTWrFmDAQMGYOLEiTh69CgePHiAJk2a4P3338ewYcO06rV48WJ8/fXXuHPnDlxdXfH2229j1qxZ6NmzJ4KCgrBy5UpN/6ysLHh4eODnn39Gz549K1xfIqoaeYoiKIpUaGDLG8D8263MPKz+7TqycgvRp4Ub+gS7wcFaqnlepRKQ+ugxCotUmjapRAx3BytYSMr+++R+jgI/nk/FLxfT8eix+U02CIIAeY4Eq28c5w2ZymHutVo/qj08HK1NPQwtDLxG8FhZjKAP9pnkvZPm94GNpf6/xry8PERFRaFly5bIy8vDBx98gJdeegmJiYnIz8/HM888A09PT+zZswdubm44e/YsVCr1H6o//fQTXn75ZcyaNQubNm1CYWEhfvrpJ4PHPH36dHz++efYsGEDZDIZCgoKEBISgunTp8Pe3h4//fQTIiIi0LhxY03QnjdvHjZt2oSlS5eia9euSEtLw+XLlwEA48aNw8SJE/H5559DJpMBADZv3gwPDw/06NHD4PER1WR/3c/Fr5czoNAKQyI0dq6HAHc7eDpa6/wFKQgCMnIUuJyegxv3c9HUpR46N3bSCk/FKgHH/8rC4TQRbK/eR7BXA7jay8r9y7aoWIVbWfm4kp6DK+lyXErPwZX0HCQ/UN+psr1vfQxs44kXWrqjvhHCryAI2PdnOqwtLdDd39lswkBRsQq7ElLgam+FsCZOpQbTDHkBlh+6hm2n76BIJQAADl7OwOzvL6Jncxc4WEtxOV2Oq/dyS51ksbQQo5lrPTR3tYePkw0kYvW5q1QCTt96gN+vZ+Lvw5oxEdLyc009iBrCfGulLFaV36maMfDWMa+88orW43Xr1sHFxQVJSUk4fvw47t+/jzNnzqBBgwYAgKZNm2r6fvzxx3jttdcwb948TVvr1q0NHkNkZCRefvllrbb//Oc/mv+eNGkSfvnlF2zfvh0dO3ZETk4OvvzySyxfvhwjR44EADRp0gRdu3bVnNOkSZPw/fffY8iQIQCADRs2YNSoUWbzlx1RVREEAamPCvDzhTTsTkzBxRT5U/vbySzgWd8a4r//3xAApD16jOx87Rk/53oy9G/tju7+DfH79Uz8cD4V9+QKABLsvJUAAHCwlqK5mx0C3ezQ3M0ezd3skF9YhCvpObicnoPL6XJcu5erFb7/7cythzhz6yHm7vkT/Vq648P+QXCqJ6tQLYpVAubu+RObTt4GAIT41Mf05wPQwU/959nldDl2J6Tij1sP4OFojQB3OwS42aGlpyMa2lXsPfWhUgmYues8dp5NAaCu7Yut3NGnhRse5hficpocl9NzcPRapibIPtu8Ido1qo8fz6fi6r1c/PJnutYxLSViWEmfhOaCIhUKi1S4mCJ/6megtbcjBrXxgL+LXRWcaeUUFRfh9KnT6NCxAywkjCdPY+61crEzv5s6mV+VaiBrqQRJ8/sY9BqVSoUceQ7s7O0qvaTBEH/99RfmzJmDkydPIjMzUzN7m5ycjMTERLRt21YTdv8tMTERb775ZoXHWiI0NFTrcXFxMT799FPExsYiJSUFCoUCCoUCtra2AIBLly5BoVCgV69epR5PJpPhjTfewPr16zFkyBAkJibi3Llz2L17d6XHSlQRKpWA+OSHuPMgH70CXbW+jq6Iuw/z8dP5NBQL6uk5QVB/PX05XY4r6Tl4+I+waiEWoUtTZ7g7PPkLJ7+wGFfv5eCv+7nIURThcnqOznuIRYCfsy18nWxxNvkhMnMV2PD7LWz4/Zamj4O1BbysCqGwsMPNrHw8eqzE6ZsPcPrmg6eO31oqQTNNMFb/BLjZQ1FUjB/OpWJ3QiqS0uTYcy4VJ25k4f9ebY1nmjXUOY56tjgPl/8+52ebNYR3A/UdLwuUxZi8NQH7k+5BJFIHwvjbDzHkyxPo2tQZmbkK7fO+/RB7zj2p2fcTu6CFh0O5vwtDCQKwYO9l7DybAolYBHsrC2TmKhBz/BZijt/S6d+ukSP++3wAOjV2AgBM6tkUl9Jy8MvFNAgAAtzsEeBuB18nW80MLqD+zN15mI9LaeoZ9LRHj7WO6+lojf6tPeDrbGv0czQWpVKJR1cEdGniBKm0cv/P1HasleEYeI1AJBIZtKwAUAfeIksJbCwtqvXOX/3794e3tze++uoreHh4QKVSITg4GIWFhbC2fvp6m/KeF4lEEATt78tKuyitJMiW+Pzzz7F06VJER0ejZcuWsLW1RWRkJAoLC/V6X0C9rKFNmza4e/cu1q9fj169esHHx6fc11Hdk1OgxIW7j/7+al2Ouw/y4SGI0Fco/7vePEURktLkmhm56xm5sLeWamY4Xe1lOHg5A3sSU5GSrQ4cDtZSTHi2CUaG+cLKwH+gAkBq9mMMXPk7svIKy+wjFgFtG9XHoDYe6NfSvcwZUmWxCjfu5yFdXqDV7mRriaYu9TTjUxarcPTafexOSEX87Ydo08gRg9p4IszPEQf2/4J+/bqgGGL8dT/3H7O5ObiangNrSwkC/g60zd3sEOhuB+/6NhCLS/+25a3uTfBW9yY4dycbU7efw/WMXIxcfxqju/iiR3MXXE5X1/pKeg6uZeRqrVsF1LO4A1p74PvEFJxNzoalhRhLh7RBqG99LD94DdvO3MGx65kA1CH42eYN8VygK+7/HYDP3HyAdHkBNp9KxicvtdT796KvvXfE2J9yByIR8PmrrfFCK3dNbU/eyIK7g5WmVq28HBDiU1/rmymRSIQgD3sEedg/9X3EYhF8nGzh42SL54PdjH4eRDUdA28dkpWVhUuXLuHLL79Et27dAADHjh3TPN+qVSt8/fXXePDgQamzvK1atcLBgwcxevToUo/fsGFDpKWlaR5fu3YN+fn55Y7r6NGjGDhwIN544w0A6n8MXLt2DYGBgQAAf39/WFtb4+DBg5qL6/6tZcuWCA0NxVdffYUtW7ZgxYoV5b4vmU5+YRH2/3kPVlJ1OGrUoOxAVJ6HeYX47WoGege5oZ7s6X+k/Zn6CMO/OlXKBTsSZGw6i/8b0kbnqzhFUTEOX7mP7xNTceDSvVK/no9LuqfTVk9mAad6lridlY+FP1/Ght9vIap3M7wa6qX3UpsCZTHe3hSPrLxCNHa2RYhPfc1zmuUE7vZaYfVppBKxZoa1vH49A1zRM8BVq/2f/4C1kkrQwsPBaLOirb0d8cPErlj48yVsPHFbZ3a5hLVUguZudrC0EOPMrQeIv/0Q8bcfAgDsrSzw9cj2miUMH7/UEuO6Ncaus3fh7miNfsHucLDRng07fj0Tw78+hR/OpeKDF4Mq9I+Ssnx17Cb2p6gnNOYPDMagtp4AUGptiahqMfDWIfXr14eTkxPWrl0Ld3d3JCcnY8aMGZrnhw0bhk8++QSDBg3CwoUL4e7ujoSEBHh4eKBz58748MMP0atXLzRp0gSvvfYaioqK8PPPP+O///0vAKBnz55YuXIlOnXqBJVKhenTp+v1VUvTpk2xY8cOHD9+HPXr18eSJUuQnp6uCbxWVlaYMmUKZsyYASsrK3Tp0gX379/Hn3/+ibFjx2qOU3Lxmo2NDV566SUjV4+M5X6OAmO/OYPzdx9p2mwsJfB3ffKVd4CbekarvKUAR67ex3+2n0NGjgLd/FPwzegOZQbnB3mFeGtjPB49VsLVXobWXo4IcLMDIGDNr9dx5FoWno8+ig/7B8FSItbMAJ+88UArILvZWyHQXT2j28y1HrLzlepZzns5uPsgH+186mNQG0/0CnSBVCLGroQULI27ipTsx/jvjvM4dzcb8wcGa30dXRpBEDBz5wVcSHmEBraW+GZMB83X97WVtaUE8wcG49nmDbFw72UUCwIC3OzQ3NVes972n7PF9+QF+OFcKvacS0VhkQorhrWFv6t2mPdztkVUePMy37NTYyd4OlojJfsx9v2ZjoFtPI1yLltOJWPxvmsAgP/09kdEJ37jRGRKDLx1iFgsxrZt2zB58mQEBwejefPmWL58OZ599lkAgKWlJfbv34+pU6eiX79+KCoqQlBQEFatWgUAePbZZ7F9+3Z89NFH+PTTT2Fvb4/u3btrjv/5559j9OjR6N69Ozw8PLBs2TLEx8eXO645c+bg5s2b6NOnD2xsbPDWW29h0KBBePToSSCaNm0abG1t8cEHHyA1NRXu7u4YP3681nGGDRuGyMhIDB8+HFZW5rdgnoAb93MxasMZJD/Ih6ONFF71rXH1Xi7yC4tx7k42zt3J1vS1EIvQzd8Zg9p6oneQq9ayoQJlMRb/cgXrf7+paTt6LRPfnLiF0V38dN63qFiFdzefRUr2Y/g42WDPu101M31KpRI2WVewO90Rl+/lYsq2RJ3Xu9rLMKC1Bwa28UQLD3uDLoYcHOKF/q3d8fXRm/i//Vew+VQyMnIUWP5aW1hblj2buO7YTexKUK/7XDm8ba0Pu/+k7wyoq70VxnVrjHHdGlf4vcRiEV4J8cLyg9fwXfxdrcArCAIOXsqAlVSCzk2cyv1HSonvE1Mwa/cFAMBzHiq83V33M0lE1YuBt4557rnnkJSUpNX2z3W3Pj4++O6778p8/csvv6yzw0IJDw8P7NunvT1bdna25r99fX111vgCQIMGDcq9wEwsFuP999/H7Nmzy+zz8OFDFBQUaM36knHlFxYZvPdzibPJDzE25gwe5ivh3cAa34zugMYN62m2rSq5AOtyeg4upclx9+Fj/HrlPn69ch/WUgkC3O1Q8q735ArNGtmITj7wcbLBgp8uYeHPlxHWxFnnK/uP917CiRtZsLGU4KsRoTpfa7vbAN+N74Tlv97A7oQUuDlYobmrHQLc7dHSU72uUt+wUxqZhQTv9miKxs62mBKbiLikexj+9UksGdIGNn+H3iKVgJv38zRrVneevQsAmP1CIMKaOFf4val8r7TzxPKD13DseibSHj2Gu4P6uoH//XEH03eog2tDO/XOCoPaeKK1t2OZxzp46R6m/u8cBAEY3sELHcS3quEMiKg8DLxU4ymVSqSlpWHGjBno1KkT2rVrZ+oh1Top2Y+x7MBVfBd/F4Hu9vjv8wEG7XEal3QPk7aeRYFShVZeDlg3sr1mGygLiRhNXeqhqUs9vNjqyWv+up+L7xNT8X1iCm5n5SMhOVvrmM71LLF4cCv0DHCFIAj4/Xomfr1yH1O2JeD7iV0gs5BAWazC5pO3NWtBlwxpg2aupa9flVmI8X6/QLzfL9Dg+uirb0t3ONvJMO6bP5CQnI0e//fbU/sPDvHCqDDfKhsPqfk42aKDXwOcvvkAO8+m4N0eTXErMw/zflBPDlhLJbif82TXiunPB+CdZ3WvJzjxVxbe2XwWRSoBg9p44MMXAvHLL7eq+WyIqDQMvFTj/f777+jRoweaNWv21NlpMlxWrgJrfvsLG0/e1lwd/2eqHCPXn0anxg3w3+cD0K5R/ace49uTt/HB9xehEoAezRti5fB2sC3n4jIAaNKwHqJ6N8N7z/njYopca5slsUiE9r4NNDO1IpEIiwe3xvPRR3A5PQczd16AjaUEP51P02zZNbmXv1lcvd7etwF2vNMZE7ck4HrGk03jRSLAq77N3zPLdmjp6YAezV24l3Q1eTXEC6dvPsB38XfxVvfGiIxNRH5hMTr6NcA3Yzrg9+uZ2P7HXfzyZzpW/3YdEZ19tC6SLFAWY8q2BBQWqdA7yBWfvdoaUBl2B04iqjoMvFTjPfvss6UulSDDFKsEnLyRhVM3snTuhgUAHf0aYGLPpjh85T42nriNkzce4OXVx9HaywED2niif2t3rR0OBEHA/+2/glW//gUAGBrqjY9fCn7qrU9LIxKJ0NLLAS29nr4bQEM7GRa90grjNv6h2eAfUG/yP7xjI0T28jfofatSUxc7/BLZvfyOVG36tXTHh3v+xM3MPLzzbTwS72TDzsoCS4a2gZVUgl6BrujR3AXPLTmMG5l52BF/FyP/Mfu+82wKMnIUcHewwophbSGViKFk4CUyGwy8RHVMfmERCpRPtta68yAf3yem4ofzqbifo9Dp39LTAf/p01yzhKGbf0OM7uqH6Lir2JmQgnN3H+Hc3Uf4+KcktPRyhJWFOtDmFKj3rAWAyOf8MaWXf5XPVj4X5Ip3nm2C/525g2eaN1TvHVvGbVyJ/slWZoG+we7YcfYuDlzKAAAsGBQMT8cn+4CLxSKMDPPFh3v+RMzxW4jo5AOxWIRilYAvj6j/YTeuW2Ojbm1GRMbBwFtBnFGsuerq704QBCw7eA0rD11Hkar0GjjaSNErwBUtPOzV20G52ZV6EwNPR2t89mprTO8bgJ/Oq29pm5CsvcsCAEjEInzyUjCGtm9UFadUqunPB2D68wHV9n5Ue7wa6oUdf18sOLCNR6lblL0S4oX/23cFNzPzcPjqffQIcMHeC2m4naXeeWRYB+/qHjYR6YGB10Al+8rm5+frdQcwMj8lN8OojbdjVKkEfB53DZduitH2UQEaOf+99VaxCrN2XcD//rir8xprqQS9Al0wqI0nujdrCEsL/WdDnevJMDLMFyPDfHE7Kw9/psrxz39PNHezQ1OXepU+L6Lq0MG3Abo3a4iHeYWYPzC41D71ZBYY0t4b647dxPrfb+LZ5g2x5jf17O6oMF+D77pJRNWD/2caSCKRwNHRERkZ6q+8bGxsKvQ1rUqlQmFhIQoKCqr11sI1kbFqJQgC8vPzkZGRAUdHR0gkNeNrx6JiFQ5ezkBW7pNby9pbW+C5QFedr06XHriKL47cBCDGc9HHMOrvMPr+zgs4fPU+xCL1HZ9e76g942qMpQYltzUlqqnEYhE2julQbr+RnX2x/vebOHotE+uO3URSmhw2lhKM7Oxb9YMkogph4K0ANzf1ld4lobciBEHA48ePYW1tzauwy2HsWjk6Omp+h+auWCUg6n/nsOdcqs5zoT718fXIUDjaWAIAfr6QhhWHrgMAPG0EpOSrsPbIDaw9cgMAYCUVY+WwdnguiLc0JaqMRk426B3oiv1J97Dgp0sAgGEdGqG+raWJR0ZEZWHgrQCRSAR3d3e4uLho3VveEEqlEkeOHEH37t1r5VfrxmTMWkmlUpPP7J66kYXP9l3BxdRH6NrUGQPbeOK5QFedu24JgoDZuy9iz7lUSCUiPNPMBSX3PjhxIwt/3H6IV9YcxzdjOiBXUYSp288BAMaE+aCV6i/U82+Pzw/8hUtpcjSwtcS6kaFoW84WYkSkn9Fd/LA/6R4AQCoRYVw33k2NyJwx8FaCRCKpcHiSSCQoKiqClZUVA285akut/kx9hM/2XcFvV+5r2g5cysCBSxmwtZSgTws3DGzriS5/38L0058vY+vpZIhFQPTQtnihlbvmdVfSczBqw2n8dT8PL60+DpmFGPmFxejS1AnTwv2xf99feKZZQ/QMdMfJG1lo6lIPLva83TKRsXRq3AABbna4nJ6Dl9p6au7ORkTmiYGXqAqoVAL2J91D4p1sXPn7VrFpjwoAABZiEYZ1aIRBbT1w6HIGvk9Mxd2Hj7EzIQU7E1LgXE+GVl4OOHRZvWRm4csttcIuoL4YbOeEMIzecAaX03MAAN4NrLFyWDtYSJ4s+xCLRQhrytvSEhmbSCTCZ4NbY8vp25ga3tzUwyGicjDwEhlZ2qPHmPq/czj+V5ZWu0gE9G/lganhzTQXd4X4NMB/wpvjbPJD7E5IxY/nU5GZq9CE3dkvBJa5pZe7gzX+N74z3tuWiKQ0OdZGhKK+rWWFl9kQkWFaejlgoVer8jsSkckx8BIZ0d4LaZi58wIePVbCWirBS+08Eeiu3tO2masdHKx1l2SIRCKE+DRAiE8DfNA/CMeuZeKXi+kI9nJARCefp76fvZUU60a1hyAIvPiRiIioDAy8RHo6di0TO8/eRVd/Z/Rp4QZbmfp/H5VKwKmbD7D51G38eD4NANDKywHRQ9ugcUPD9qCVSsToEeCCHgEuBr2OYZeIiKhsJt8AdvXq1fDz84OVlRVCQkJw9OjRp/ZftWoVAgMDYW1tjebNm2Pjxo1az8fExEAkEun8FBQUVOVpUC0XeyYZIzecxs6EFET97xxCFsRh0tYEfPxTErosOoRhX53Ej+fTIBIB7/Zogh3vhBkcdomIiKhqmHSGNzY2FpGRkVi9ejW6dOmCL7/8En379kVSUhIaNdJdt7hmzRrMnDkTX331Fdq3b4/Tp0/jzTffRP369dG/f39NP3t7e1y5ckXrtVZWvEKdDFdyO97oA9cAAN38nXH34WPczMzDD//YG9fOygL9gt0xrGMjtPF2NNFoiYiIqDQmDbxLlizB2LFjMW7cOABAdHQ09u3bhzVr1mDhwoU6/Tdt2oS3334bQ4cOBQA0btwYJ0+exKJFi7QCr0gkqjE3FiDzVVSswuzdF7HtzB0AwMQeTTE1vBkA4PzdR9hzLhUP8wsRHuSKZ5u76Nz1jIiIiMyDyQJvYWEh4uPjMWPGDK328PBwHD9+vNTXKBQKnZlaa2trnD59GkqlUrNHa25uLnx8fFBcXIw2bdrgo48+Qtu2bcsci0KhgEKh0DyWy+UA1Dc8qKor3kuOyyvqy2eKWuUpijDlf+dx+GomxCJgbv9ADGvvjaKiIgBAkJstgtz8//EKFZRKVbWN72n42TIM66U/1sowrJdhWC/9sVZqhpy/SBAEoQrHUqbU1FR4enri999/R1hYmKb9k08+wTfffKOzJAEA3n//fWzYsAE//vgj2rVrh/j4eLzwwgvIyMhAamoq3N3dcfLkSVy/fh0tW7aEXC7HsmXLsHfvXpw7dw7+/v46xwSAuXPnYt68eTrtW7ZsgY2NjfFOmmoEeSGw9rIEd/JEkIoFjPRXoWUDk/xvQkRERGXIz8/H8OHD8ejRI9jb2z+1r8l3afj31eVP215pzpw5SE9PR6dOnSAIAlxdXTFq1CgsXrxYc8ezTp06oVOnTprXdOnSBe3atcOKFSuwfPnyUo87c+ZMREVFaR7L5XJ4e3sjPDy83AJWlFKpRFxcHHr37l2j7x5WHaqzVjcz8zB241ncyXuM+jZSfPlGW7StYWty+dkyDOulP9bKMKyXYVgv/bFWaiXfyOvDZIHX2dkZEokE6enpWu0ZGRlwdXUt9TXW1tZYv349vvzyS9y7dw/u7u5Yu3Yt7Ozs4Oxc+t2kxGIx2rdvj2vXrpU5FplMBplMptMulUqr/INUHe9RWxi7VsUqARHrTuHkjSc3iFD9PZHbqIENvhnTAX7OtkZ7v+rGz5ZhWC/9sVaGYb0Mw3rpr67XypBzN9m2ZJaWlggJCUFcXJxWe1xcnNYSh9JIpVJ4eXlBIpFg27ZtePHFFyEWl34qgiAgMTER7u7upT5PddfPF9Nw/K8sqARofgCgXSNH7HgnrEaHXSIiInrCpEsaoqKiEBERgdDQUHTu3Blr165FcnIyxo8fD0C91CAlJUWz1+7Vq1dx+vRpdOzYEQ8fPsSSJUtw8eJFfPPNN5pjzps3D506dYK/vz/kcjmWL1+OxMRErFq1yiTnSOZJEASs+e0vAMA7zzbB6C6+AAARRHCuZ8kbORAREdUiJg28Q4cORVZWFubPn4+0tDQEBwdj79698PFR3041LS0NycnJmv7FxcX4/PPPceXKFUilUvTo0QPHjx+Hr6+vpk92djbeeustpKenw8HBAW3btsWRI0fQoUOH6j49MmNHr2Xiz1Q5rKUSvNWtMerbWpp6SERERFRFTH7R2oQJEzBhwoRSn4uJidF6HBgYiISEhKceb+nSpVi6dKmxhke1VMns7rAOjRh2iYiIajmT31qYqLolJD/EiRtZkEpEGNfNz9TDISIioirGwEt1Tsns7qA2nvBwtDbxaIiIiKiqMfBSnXI9Iwf7k+5BJALefqaJqYdDRERE1YCBl+qMR4+VmPdDEgCgT5AbmrrUM/GIiIiIqDqY/KI1osoQBAHfnrwNqUSMl9t5wdKi9H/DnbqRhaj/nUNK9mNIJSJM7Nm0mkdKREREpsLASzXajrMpmPP9nwCAVb9dR1TvZhjY2hNisQiCICBdXoCNJ27ji8N/QRAAHycbRA9tg2BPBxOPnIiIiKoLAy/VWA/yCvHxT+olClZSMe48eIz3Ys/hi99uwMFGiivpOXj0WKnpPyTUCx/2bwFbGT/2REREdQn/5iezIwgC7jx4DO8G1k+949nHP13Cw3wlAtzs8L/xnbHp75ncK/dyNH0kYhH8Xephci9/9GvJ20sTERHVRQy8ZFYEQcD7uy5i6+lkDOvgjYUvtyq13/G/MrHj7F2IRMAnL7eEvZUU7/Zoitc7NsIP59NgaylBczc7NHWpB5mFpJrPgoiIiMwJAy+ZDUEQ8MneS9h6Wn076a2n76C7f0M8F+Cs1a9AWYxZuy4CAN7o6IN2jeprnnO0sUREJ5/qGzQRERGZPW5LRmZjxaHr+OroTQBAp8YNAAAzd11AurxA00cQBEQfuIabmXlwsZNh2vPNTTJWIiIiqjkYeMksrD92E0virgIAPngxCBvHdESwpz2y85WYvvMiVIJ6H92JWxPwxWH1ndLmDmgBeyupKYdNRERENQCXNJBJFSiL8enPlxFz/BYAIPI5f4zp6gcAiB7aFi+uOIrjfz0AcsVYtPI40uUKWIhFmBreHH2D3Uw4ciIiIqopGHjJZC6nyzFla6JmV4V3ezTBlF7+muebutTDrBeCMGf3RRy/JwaggJ+zLaKHtkFrb0fTDJqIiIhqHAZeMolvjt/Cxz9dQmGxCs71ZPjs1Vbo0dxFp98bHRvh6NUM7E/KwNBQT3zQP5j76BIREZFBmByo2n115AY+3nsJANArwAWLBreCcz1ZqX1FIhFWDG2N2D0/Y9jAFpBK+ZElIiIiwzA9ULXaejpZE3bfe64ZJvdq+tSbSwCAWCyCg2V1jI6IiIhqIwZeqjZ7zqXi/V0XAADjn2mCKc/5l/MKIiIiosrjtmRULX69nIGo2EQIAvB6x0aYzv1ziYiIqJow8FKVu5+jwJRtCShSCRjYxgMfDQwudxkDERERkbEw8FKVW/BTEuQFRWjhYY//e7U1xGKGXSIiIqo+DLxkFLez8jBqw2lsPZ2s1X7k6n18n5gKsQhY+HJLSCX8yBEREVH14kVrVGmCIGDWros4dj0Tv125j1uZeZj+fAAURSrM3n0RADAyzBetvBxNO1AiIiKqkxh4qdJ+vZKBY9czIRGLUKwS8OWRG0iXF8DFTobkB/lwd7DC1HBepEZERESmwcBLlaIsVmHBT+p9dcd180MzFztM33Ee3yemavrMG9AC9Xh3NCIiIjIRphCqlC2nknHjfh6cbC3xbo+msLeSoqGdDO98G4+8wmKEB7kivIWbqYdJREREdRgDL1XYo3wllh64CgB4r3cz2FtJAQDdmzXErne7IC7pHt7o6GPKIRIREREx8FLFrTh0Ddn5Svi71MNr7b21nmvmaodmrnYmGhkRERHRE9wjiiokNfsxvjlxCwAw64VAWHC7MSIiIjJTTClUITvi70JZLKCDbwM829zF1MMhIiIiKhMDLxlMEAR8d/YuAGDov5YyEBEREZkbBl4y2JlbD3E7Kx+2lhL0bckdGIiIiMi8MfCSwb6LvwMAeKGVO2wsed0jERERmTcGXjJIfmERfjqfBgAYHMLlDERERGT+GHjJID9fSEdeYTEaNbBBe9/6ph4OERERUblMHnhXr14NPz8/WFlZISQkBEePHn1q/1WrViEwMBDW1tZo3rw5Nm7cqNNnx44dCAoKgkwmQ1BQEHbt2lVVw69zvotXX6w2OMQLIpHIxKMhIiIiKp9JA29sbCwiIyMxa9YsJCQkoFu3bujbty+Sk5NL7b9mzRrMnDkTc+fOxZ9//ol58+bh3XffxQ8//KDpc+LECQwdOhQRERE4d+4cIiIiMGTIEJw6daq6TqvWuvMgHyduZEEkAl4J8TL1cIiIiIj0YtLAu2TJEowdOxbjxo1DYGAgoqOj4e3tjTVr1pTaf9OmTXj77bcxdOhQNG7cGK+99hrGjh2LRYsWafpER0ejd+/emDlzJgICAjBz5kz06tUL0dHR1XRWtYcgCMjOL8TDPPXPtjPqf4iENXGCp6O1iUdHREREpB+TXWJfWFiI+Ph4zJgxQ6s9PDwcx48fL/U1CoUCVlZWWm3W1tY4ffo0lEolpFIpTpw4gffee0+rT58+fZ4aeBUKBRQKheaxXC4HACiVSiiVSkNOS28lx62q41fGX/fz8MP5NPxwPg3JDx7rPP9Sa/dqHbc518ocsV6GYb30x1oZhvUyDOulP9ZKzZDzN1ngzczMRHFxMVxdXbXaXV1dkZ6eXupr+vTpg6+//hqDBg1Cu3btEB8fj/Xr10OpVCIzMxPu7u5IT0836JgAsHDhQsybN0+nff/+/bCxsanA2ekvLi6uSo9viORc4H83JLiTV/baXA8bAcKdROxNTay+gf3NnGpVE7BehmG99MdaGYb1Mgzrpb+6Xqv8/Hy9+5p8E9V/X/gkCEKZF0PNmTMH6enp6NSpEwRBgKurK0aNGoXFixdDIpFU6JgAMHPmTERFRWkey+VyeHt7Izw8HPb29hU5rXIplUrExcWhd+/ekEqlVfIehricnoM5685AXlAEC7EIXZs6YUBrd/Rs3hDW0n/WVre+Vc3camXuWC/DsF76Y60Mw3oZhvXSH2ulVvKNvD5MFnidnZ0hkUh0Zl4zMjJ0ZmhLWFtbY/369fjyyy9x7949uLu7Y+3atbCzs4OzszMAwM3NzaBjAoBMJoNMJtNpl0qlVf5Bqo73KM/NzDyM/uYs5AVFCPGpj7URIXCqp1sPUzOHWtUkrJdhWC/9sVaGYb0Mw3rpr67XypBzN9lFa5aWlggJCdGZjo+Li0NYWNhTXyuVSuHl5QWJRIJt27bhxRdfhFisPpXOnTvrHHP//v3lHrOuSs1+jDe+PoXMXAWC3O2xflR7swy7RERERBVl0iUNUVFRiIiIQGhoKDp37oy1a9ciOTkZ48ePB6BeapCSkqLZa/fq1as4ffo0OnbsiIcPH2LJkiW4ePEivvnmG80xp0yZgu7du2PRokUYOHAgvv/+exw4cADHjh0zyTmas0ePlXhj3SmkZD9GY2dbbBzbAQ7WdfdfikRERFQ7mTTwDh06FFlZWZg/fz7S0tIQHByMvXv3wsfHBwCQlpamtSdvcXExPv/8c1y5cgVSqRQ9evTA8ePH4evrq+kTFhaGbdu2Yfbs2ZgzZw6aNGmC2NhYdOzYsbpPz+x9e/I2btzPg4eDFb4d1xHOnNklIiKiWsjkF61NmDABEyZMKPW5mJgYrceBgYFISEgo95iDBw/G4MGDjTG8WkulErD1tPofE1HhzeHBfXWJiIioljL5rYXJNI5cu4+7Dx/D3soCL7ZyN/VwiIiIiKoMA28dteWUenb35XZesPrHtmNEREREtQ0Dbx10T16Ag5czAACvd2xk4tEQERERVS0G3joo9swdFKsEtPetD39XO1MPh4iIiKhKMfDWMcUqAdv+vlhtOGd3iYiIqA5g4K1jDl/NQOqjAjjaSNE3mBerERERUe3HwFvHlFysNpgXqxEREVEdwcBbh5y/m41Df1+sNozLGYiIiKiOYOCtI/ILixC5LREqAejf2gNNGtYz9ZCIiIiIqgUDbx2x4KdLuJGZB3cHKywYGGzq4RARERFVGwbeOiAu6R62nEqGSAR8/mprONhITT0kIiIiomrDwFvLZeQUYPqO8wCAN7s1RlhTZxOPiIiIiKh6MfDWYnmKIkzemoAHeYUIdLfH1PBmph4SERERUbWzMPUAqGpk5BRgTMwZXEyRw1oqwbLX2kBmwW3IiIiIqO5h4K2F/rqfi5HrT+Puw8dwsrXEulHt0Yy3ECYiIqI6ioG3ljl/Nxsj1p9Gdr4Svk42iBndAb7OtqYeFhEREZHJMPDWIspiFSK3JSI7X4nW3o5YPzIUTvVkph4WERERkUkx8NYi3568jRuZeXCytcSmsR1gb8Xtx4iIiIi4S0MtkZ1fiOgD1wAAUeHNGHaJiIiI/sbAW0usOHQdjx4r0cy1HoaGept6OERERERmg4G3FriZmYeNJ24BAGa/EAQLCX+tRERERCWYjGqBhXsvQVks4NnmDdG9WUNTD4eIiIjIrDDw1nAn/srC/qR7kIhFmNUv0NTDISIiIjI7DLw1WLFKwIKfkgAAwzs0gj9vLkFERESkg4G3Btt59i7+TJXDzsoCkc/5m3o4RERERGaJgbeGyi8swmf7rgAAJvVsyhtMEBEREZWBgbeG+uLwDWTkKNCogQ1GhvmaejhEREREZouBtwZKe/QYa4/8BQCY2TcAMguJiUdEREREZL4YeGugz365ggKlCu196+P5YDdTD4eIiIjIrDHw1jC3MvOwMyEFgPomEyKRyMQjIiIiIjJvDLw1zLWMXABAS08HtPZ2NO1giIiIiGoABt4a5p68AADg5mBl4pEQERER1QwMvDVMxt+B19We25ARERER6YOBt4a5J1cAAFzsOMNLREREpA8G3homI4czvERERESGYOCtYTQzvPac4SUiIiLSh8kD7+rVq+Hn5wcrKyuEhITg6NGjT+2/efNmtG7dGjY2NnB3d8fo0aORlZWleT4mJgYikUjnp6CgoKpPpVpoZni5pIGIiIhILyYNvLGxsYiMjMSsWbOQkJCAbt26oW/fvkhOTi61/7FjxzBixAiMHTsWf/75J7Zv344zZ85g3LhxWv3s7e2Rlpam9WNlVfMDorJYhczcQgBc0kBERESkLwtTvvmSJUswduxYTWCNjo7Gvn37sGbNGixcuFCn/8mTJ+Hr64vJkycDAPz8/PD2229j8eLFWv1EIhHc3PS/A5lCoYBCodA8lsvlAAClUgmlUmnweemj5LiGHD/tkXp210IsQj2pqMrGZm4qUqu6jPUyDOulP9bKMKyXYVgv/bFWaoacv0gQBKEKx1KmwsJC2NjYYPv27XjppZc07VOmTEFiYiIOHz6s85rjx4+jR48e2LVrF/r27YuMjAwMGTIEgYGB+OKLLwColzSMGzcOnp6eKC4uRps2bfDRRx+hbdu2ZY5l7ty5mDdvnk77li1bYGNjY4SzNY5bOcDSixZwtBQwL6TY1MMhIiIiMpn8/HwMHz4cjx49gr29/VP7mmyGNzMzE8XFxXB1ddVqd3V1RXp6eqmvCQsLw+bNmzF06FAUFBSgqKgIAwYMwIoVKzR9AgICEBMTg5YtW0Iul2PZsmXo0qULzp07B39//1KPO3PmTERFRWkey+VyeHt7Izw8vNwCVpRSqURcXBx69+4NqVSq12vikjKAi4nwcXFEv34dq2Rc5qgitarLWC/DsF76Y60Mw3oZhvXSH2ulVvKNvD5MuqQBUC8/+CdBEHTaSiQlJWHy5Mn44IMP0KdPH6SlpWHatGkYP3481q1bBwDo1KkTOnXqpHlNly5d0K5dO6xYsQLLly8v9bgymQwyme6aWKlUWuUfJEPeIytfPXXv5mBVJz/g1fH7qE1YL8OwXvpjrQzDehmG9dJfXa+VIedussDr7OwMiUSiM5ubkZGhM+tbYuHChejSpQumTZsGAGjVqhVsbW3RrVs3LFiwAO7u7jqvEYvFaN++Pa5du2b8k6hmJVuSuXJLMiIiIiK9mWyXBktLS4SEhCAuLk6rPS4uDmFhYaW+Jj8/H2Kx9pAlEgkA9cxwaQRBQGJiYqlhuKa59/dthV3suEMDERERkb5MuqQhKioKERERCA0NRefOnbF27VokJydj/PjxANRra1NSUrBx40YAQP/+/fHmm29izZo1miUNkZGR6NChAzw8PAAA8+bNQ6dOneDv7w+5XI7ly5cjMTERq1atMtl5Gsu9HN50goiIiMhQJg28Q4cORVZWFubPn4+0tDQEBwdj79698PHxAQCkpaVp7ck7atQo5OTkYOXKlZg6dSocHR3Rs2dPLFq0SNMnOzsbb731FtLT0+Hg4IC2bdviyJEj6NChQ7Wfn7FlyEtuK8zAS0RERKQvk1+0NmHCBEyYMKHU52JiYnTaJk2ahEmTJpV5vKVLl2Lp0qXGGp5ZycgpWcPLJQ1ERERE+jL5rYVJP4qiYjzI+/sua7ytMBEREZHeGHhriPt/z+5aSsRwtKm7W5AQERERGYqBt4Yo2ZKsoZ2szH2KiYiIiEgXA28NcT+n5II1rt8lIiIiMgQDbw3Bm04QERERVQwDbw1xj1uSEREREVUIA28N8c81vERERESkPwbeGiIjhzO8RERERBXBwFtDZMh50wkiIiKiimDgrSHucYaXiIiIqEIYeGuAAmUxsvOVAHiXNSIiIiJDMfDWAJq7rFmIYW9tYeLREBEREdUsDLw1wJMtyXiXNSIiIiJDMfDWABl/z/ByOQMRERGR4Rh4awDedIKIiIio4hh4a4CSm064cEsyIiIiIoMx8NYAGX/P8LpwSQMRERGRwRh4a4Ane/ByhpeIiIjIUAy8NcA9zV3WOMNLREREZCgG3hogQ84ZXiIiIqKKYuA1c8piFeQFRQAAJ1sGXiIiIiJDGRx4fX19MX/+fCQnJ1fFeOhfFEUqzX9bSSUmHAkRERFRzWRw4J06dSq+//57NG7cGL1798a2bdugUCiqYmwEoPAfgdfSghPyRERERIYyOEFNmjQJ8fHxiI+PR1BQECZPngx3d3dMnDgRZ8+erYox1mklgddCLIJEzNsKExERERmqwlOGrVu3xrJly5CSkoIPP/wQX3/9Ndq3b4/WrVtj/fr1EATBmOOssxRFxQA4u0tERERUURYVfaFSqcSuXbuwYcMGxMXFoVOnThg7dixSU1Mxa9YsHDhwAFu2bDHmWOukkhleBl4iIiKiijE48J49exYbNmzA1q1bIZFIEBERgaVLlyIgIEDTJzw8HN27dzfqQOuqkovWLCUMvEREREQVYXDgbd++PXr37o01a9Zg0KBBkEqlOn2CgoLw2muvGWWAdV1hMWd4iYiIiCrD4MB748YN+Pj4PLWPra0tNmzYUOFB0RNc0kBERERUOQanqIyMDJw6dUqn/dSpU/jjjz+MMih6opBLGoiIiIgqxeAU9e677+LOnTs67SkpKXj33XeNMih6oiTwyjjDS0RERFQhBqeopKQktGvXTqe9bdu2SEpKMsqg6Amu4SUiIiKqHINTlEwmw71793Ta09LSYGFR4V3OqAxcw0tERERUOQanqN69e2PmzJl49OiRpi07Oxvvv/8+evfubdTBEdfwEhEREVWWwVOyn3/+Obp37w4fHx+0bdsWAJCYmAhXV1ds2rTJ6AOs6xRc0kBERERUKQanKE9PT5w/fx6LFy9GUFAQQkJCsGzZMly4cAHe3t4GD2D16tXw8/ODlZUVQkJCcPTo0af237x5M1q3bg0bGxu4u7tj9OjRyMrK0uqzY8cOBAUFQSaTISgoCLt27TJ4XObiyUVrEhOPhIiIiKhmqtCiW1tbW7z11luVfvPY2FhERkZi9erV6NKlC7788kv07dsXSUlJaNSokU7/Y8eOYcSIEVi6dCn69++PlJQUjB8/HuPGjdOE2hMnTmDo0KH46KOP8NJLL2HXrl0YMmQIjh07ho4dO1Z6zNWNa3iJiIiIKqfCV5klJSUhOTkZhYWFWu0DBgzQ+xhLlizB2LFjMW7cOABAdHQ09u3bhzVr1mDhwoU6/U+ePAlfX19MnjwZAODn54e3334bixcv1vSJjo7WrDMGgJkzZ+Lw4cOIjo7G1q1bSx2HQqGAQqHQPJbL5QAApVIJpVKp9/kYouS45R3/caH6eQtx+X1rK31rRWqsl2FYL/2xVoZhvQzDeumPtVIz5PxFgiAIhhz8xo0beOmll3DhwgWIRCKUvFwkEgEAiouL9TpOYWEhbGxssH37drz00kua9ilTpiAxMRGHDx/Wec3x48fRo0cP7Nq1C3379kVGRgaGDBmCwMBAfPHFFwCARo0a4b333sN7772ned3SpUsRHR2N27dvlzqWuXPnYt68eTrtW7ZsgY2NjV7nU1V+SBbjQIoY3d1UeMVPZdKxEBEREZmL/Px8DB8+HI8ePYK9vf1T+xo8wztlyhT4+fnhwIEDaNy4MU6fPo2srCxMnToV//d//6f3cTIzM1FcXAxXV1etdldXV6Snp5f6mrCwMGzevBlDhw5FQUEBioqKMGDAAKxYsULTJz093aBjAupZ4KioKM1juVwOb29vhIeHl1vAilIqlYiLi0Pv3r0hlUrL7Hfu5ytAym00a9oY/fo0q5KxmDt9a0VqrJdhWC/9sVaGYb0Mw3rpj7VSK/lGXh8GB94TJ07g0KFDaNiwIcRiMcRiMbp27YqFCxdi8uTJSEhIMOh4JTPDJQRB0GkrkZSUhMmTJ+ODDz5Anz59kJaWhmnTpmH8+PFYt25dhY4JqPcWlslkOu1SqbTKP0jlvUfR3/Pv1pYWdfpDDVTP76M2Yb0Mw3rpj7UyDOtlGNZLf3W9Voacu8GBt7i4GPXq1QMAODs7IzU1Fc2bN4ePjw+uXLmi93GcnZ0hkUh0Zl4zMjJ0ZmhLLFy4EF26dMG0adMAAK1atYKtrS26deuGBQsWwN3dHW5ubgYd09xxH14iIiKiyjE4RQUHB+P8+fMAgI4dO2Lx4sX4/fffMX/+fDRu3Fjv41haWiIkJARxcXFa7XFxcQgLCyv1Nfn5+RCLtYcskai36ypZS9y5c2edY+7fv7/MY5o77tJAREREVDkGz/DOnj0beXl5AIAFCxbgxRdfRLdu3eDk5ITY2FiDjhUVFYWIiAiEhoaic+fOWLt2LZKTkzF+/HgA6rW1KSkp2LhxIwCgf//+ePPNN7FmzRrNkobIyEh06NABHh4eANRrjLt3745FixZh4MCB+P7773HgwAEcO3bM0FM1C7zxBBEREVHlGBx4+/Tpo/nvxo0bIykpCQ8ePED9+vWfuk62NEOHDkVWVhbmz5+PtLQ0BAcHY+/evfDx8QEApKWlITk5WdN/1KhRyMnJwcqVKzF16lQ4OjqiZ8+eWLRokaZPWFgYtm3bhtmzZ2POnDlo0qQJYmNja+QevABneImIiIgqy6DAW1RUBCsrKyQmJiI4OFjT3qBBgwoPYMKECZgwYUKpz8XExOi0TZo0CZMmTXrqMQcPHozBgwdXeEzmhGt4iYiIiCrHoBRlYWEBHx8fvffapcrjDC8RERFR5RicombPno2ZM2fiwYMHVTEe+pfCv9fwyhh4iYiIiCrE4DW8y5cvx/Xr1+Hh4QEfHx/Y2tpqPX/27FmjDY6ezPDKLCQmHgkRERFRzWRw4B00aFAVDIPKwiUNRERERJVjcOD98MMPq2IcVIZCbktGREREVClMUWZOoVRfIMhdGoiIiIgqxuAZXrFY/NT9drmDg3FxhpeIiIiocgwOvLt27dJ6rFQqkZCQgG+++Qbz5s0z2sBITcE1vERERESVYnDgHThwoE7b4MGD0aJFC8TGxmLs2LFGGRip8cYTRERERJVjtBTVsWNHHDhwwFiHIwCCIHAfXiIiIqJKMkqKevz4MVasWAEvLy9jHI7+VqQSIAjq/+aSBiIiIqKKMXhJQ/369bUuWhMEATk5ObCxscG3335r1MHVdSXLGQAGXiIiIqKKMjjwLl26VCvwisViNGzYEB07dkT9+vWNOri6Tivwcg0vERERUYUYHHhHjRpVBcOg0pSs3xWLAAsGXiIiIqIKMThFbdiwAdu3b9dp3759O7755hujDIrUeFthIiIiosozOEl9+umncHZ21ml3cXHBJ598YpRBkVrJHrwyC4mJR0JERERUcxkceG/fvg0/Pz+ddh8fHyQnJxtlUKTGGV4iIiKiyjM4Sbm4uOD8+fM67efOnYOTk5NRBkVqmtsKc/0uERERUYUZnKRee+01TJ48Gb/++iuKi4tRXFyMQ4cOYcqUKXjttdeqYox1lkJZDIA3nSAiIiKqDIN3aViwYAFu376NXr16wcJC/XKVSoURI0ZwDa+RaWZ4GXiJiIiIKszgwGtpaYnY2FgsWLAAiYmJsLa2RsuWLeHj41MV46vTuIaXiIiIqPIMDrwl/P394e/vb8yx0L9oAi/X8BIRERFVmMFJavDgwfj000912j/77DO8+uqrRhkUqXFJAxEREVHlGZykDh8+jBdeeEGn/fnnn8eRI0eMMihSU3BJAxEREVGlGZykcnNzYWlpqdMulUohl8uNMihS45IGIiIiosozOEkFBwcjNjZWp33btm0ICgoyyqBIjRetEREREVWewRetzZkzB6+88gr++usv9OzZEwBw8OBBbNmyBd99953RB1iXcQ0vERERUeUZHHgHDBiA3bt345NPPsF3330Ha2trtG7dGocOHYK9vX1VjLHOKpnh5Y0niIiIiCquQtuSvfDCC5oL17Kzs7F582ZERkbi3LlzKC4uNuoA67IngVdi4pEQERER1VwVnjo8dOgQ3njjDXh4eGDlypXo168f/vjjD2OOrc7jkgYiIiKiyjNohvfu3buIiYnB+vXrkZeXhyFDhkCpVGLHjh28YK0KcJcGIiIiosrTO0n169cPQUFBSEpKwooVK5CamooVK1ZU5djqPEWRenkIZ3iJiIiIKk7vGd79+/dj8uTJeOedd3hL4WrCG08QERERVZ7eSero0aPIyclBaGgoOnbsiJUrV+L+/ftVObY6j0saiIiIiCpP7yTVuXNnfPXVV0hLS8Pbb7+Nbdu2wdPTEyqVCnFxccjJyanKcdZJvPEEERERUeUZnKRsbGwwZswYHDt2DBcuXMDUqVPx6aefwsXFBQMGDDB4AKtXr4afnx+srKwQEhKCo0ePltl31KhREIlEOj8tWrTQ9ImJiSm1T0FBgcFjMzXu0kBERERUeZVKUs2bN8fixYtx9+5dbN261eDXx8bGIjIyErNmzUJCQgK6deuGvn37Ijk5udT+y5YtQ1pamubnzp07aNCgAV599VWtfvb29lr90tLSYGVlVaFzNCXeeIKIiIio8oySpCQSCQYNGoQ9e/YY9LolS5Zg7NixGDduHAIDAxEdHQ1vb2+sWbOm1P4ODg5wc3PT/Pzxxx94+PAhRo8erdVPJBJp9XNzc6vwuZkS1/ASERERVV6F7rRmDIWFhYiPj8eMGTO02sPDw3H8+HG9jrFu3To899xz8PHx0WrPzc2Fj48PiouL0aZNG3z00Udo27ZtmcdRKBRQKBSax3K5HACgVCqhVCr1PSWDlBz3accv2ZZMLBKqbBw1gT61oidYL8OwXvpjrQzDehmG9dIfa6VmyPmLBEEQqnAsZUpNTYWnpyd+//13hIWFado/+eQTfPPNN7hy5cpTX5+WlgZvb29s2bIFQ4YM0bSfPHkS169fR8uWLSGXy7Fs2TLs3bsX586dK3M7tblz52LevHk67Vu2bIGNjU0Fz7DyPj0nQVq+CO8EFiPA0SS/JiIiIiKzlJ+fj+HDh+PRo0ewt7d/al+TzfCWEIlEWo8FQdBpK01MTAwcHR0xaNAgrfZOnTqhU6dOmsddunRBu3btsGLFCixfvrzUY82cORNRUVGax3K5HN7e3ggPDy+3gBWlVCoRFxeH3r17QyqVlton+uoxID8f3cI6ob1v/SoZR02gT63oCdbLMKyX/lgrw7BehmG99MdaqZV8I68PkwVeZ2dnSCQSpKena7VnZGTA1dX1qa8VBAHr169HREQELC0tn9pXLBajffv2uHbtWpl9ZDIZZDKZTrtUKq3yD9LT3qOwWD2ra2NlWac/0CWq4/dRm7BehmG99MdaGYb1Mgzrpb+6XitDzt1kV0NZWloiJCQEcXFxWu1xcXFaSxxKc/jwYVy/fh1jx44t930EQUBiYiLc3d0rNV5T0GxLxovWiIiIiCrMpEsaoqKiEBERgdDQUHTu3Blr165FcnIyxo8fD0C91CAlJQUbN27Uet26devQsWNHBAcH6xxz3rx56NSpE/z9/SGXy7F8+XIkJiZi1apV1XJOxsQbTxARERFVnkkD79ChQ5GVlYX58+cjLS0NwcHB2Lt3r2bXhbS0NJ09eR89eoQdO3Zg2bJlpR4zOzsbb731FtLT0+Hg4IC2bdviyJEj6NChQ5Wfj7GV7NLAfXiJiIiIKs7kF61NmDABEyZMKPW5mJgYnTYHBwfk5+eXebylS5di6dKlxhqeSXGGl4iIiKjymKTMVFGxCqq/dyLjGl4iIiKiimOSMlMlF6wBnOElIiIiqgwmKTNVspwBYOAlIiIiqgwmKTNVEnhFIsBCXP6NOIiIiIiodAy8ZkpR9GQPXn3uPEdEREREpWPgNVOam05wOQMRERFRpTBNmamSJQ3cg5eIiIiocpimzNSTwCsx8UiIiIiIajYGXjPFJQ1ERERExsE0ZaYK/3HRGhERERFVHNOUmeJthYmIiIiMg2nKTCkYeImIiIiMgmnKTCmKigFwSQMRERFRZTFNmSkuaSAiIiIyDqYpM8VdGoiIiIiMg2nKTHGGl4iIiMg4mKbMlObGE1zDS0RERFQpTFNmijO8RERERMbBNGWmuIaXiIiIyDiYpswU77RGREREZBxMU2aq5MYTMil/RURERESVwTRlpjRLGiQSE4+EiIiIqGZj4DVTvGiNiIiIyDiYpswUAy8RERGRcTBNmSkGXiIiIiLjYJoyU4qiYgC88QQRERFRZTFNmSnuw0tERERkHExTZopLGoiIiIiMg2nKTPHGE0RERETGwTRlphSc4SUiIiIyCqYpM8U1vERERETGwTRlpriGl4iIiMg4mKbMFNfwEhERERkH05SZKlnSYCXlr4iIiIioMpimzNSTGV6JiUdCREREVLOZPPCuXr0afn5+sLKyQkhICI4ePVpm31GjRkEkEun8tGjRQqvfjh07EBQUBJlMhqCgIOzatauqT8PouIaXiIiIyDhMmqZiY2MRGRmJWbNmISEhAd26dUPfvn2RnJxcav9ly5YhLS1N83Pnzh00aNAAr776qqbPiRMnMHToUERERODcuXOIiIjAkCFDcOrUqeo6rUpTqQQUqQQADLxERERElWXSNLVkyRKMHTsW48aNQ2BgIKKjo+Ht7Y01a9aU2t/BwQFubm6anz/++AMPHz7E6NGjNX2io6PRu3dvzJw5EwEBAZg5cyZ69eqF6OjoajqryitZvwsw8BIRERFVloWp3riwsBDx8fGYMWOGVnt4eDiOHz+u1zHWrVuH5557Dj4+Ppq2EydO4L333tPq16dPn6cGXoVCAYVCoXksl8sBAEqlEkqlUq+xGKrkuKUdP/fxkzaRqhhKpVAlY6gpnlYr0sV6GYb10h9rZRjWyzCsl/5YKzVDzt9kgTczMxPFxcVwdXXVand1dUV6enq5r09LS8PPP/+MLVu2aLWnp6cbfMyFCxdi3rx5Ou379++HjY1NuWOpjLi4OJ02eSFQ8quJ2/cLRKIqHUKNUVqtqGysl2FYL/2xVoZhvQzDeumvrtcqPz9f774mC7wlRP9Kc4Ig6LSVJiYmBo6Ojhg0aFCljzlz5kxERUVpHsvlcnh7eyM8PBz29vbljqUilEol4uLi0Lt3b0ilUq3nUrIfA/FHYWkhxgsv9KuS969JnlYr0sV6GYb10h9rZRjWyzCsl/5YK7WSb+T1YbLA6+zsDIlEojPzmpGRoTND+2+CIGD9+vWIiIiApaWl1nNubm4GH1Mmk0Emk+m0S6XSKv8glfYeKqiXV8gk4jr9Qf636vh91Casl2FYL/2xVoZhvQzDeumvrtfKkHM32RVRlpaWCAkJ0ZmOj4uLQ1hY2FNfe/jwYVy/fh1jx47Vea5z5846x9y/f3+5xzQnJRet8YI1IiIiosoz6ZKGqKgoREREIDQ0FJ07d8batWuRnJyM8ePHA1AvNUhJScHGjRu1Xrdu3Tp07NgRwcHBOsecMmUKunfvjkWLFmHgwIH4/vvvceDAARw7dqxazskYuAcvERERkfGYNPAOHToUWVlZmD9/PtLS0hAcHIy9e/dqdl1IS0vT2ZP30aNH2LFjB5YtW1bqMcPCwrBt2zbMnj0bc+bMQZMmTRAbG4uOHTtW+fkYCwMvERERkfGY/KK1CRMmYMKECaU+FxMTo9Pm4OBQ7lV5gwcPxuDBg40xPJN4clthBl4iIiKiymKiMkOKv9fwyqT89RARERFVFhOVGeIMLxEREZHxMFGZIa7hJSIiIjIeJioz9CTwSkw8EiIiIqKaj4HXDGn24eWSBiIiIqJKY6IyQwplMQBAxiUNRERERJXGRGWGeKc1IiIiIuNhojJD3KWBiIiIyHiYqMwQd2kgIiIiMh4mKjOk4JIGIiIiIqNhojJDnOElIiIiMh4mKjPENbxERERExsNEZYZKAq9Myl8PERERUWUxUZkh3niCiIiIyHiYqMyQZoaXa3iJiIiIKo2JygzxojUiIiIi42GiMkO80xoRERGR8TBRmSGFZpcGiYlHQkRERFTzMfCaIQWXNBAREREZDROVGVIoiwEAVtyWjIiIiKjSmKjMUE5BEQDAzkpq4pEQERER1XwMvGYop0AJAKgnszDxSIiIiIhqPgZeMyMIAnIV6hleeysGXiIiIqLKYuA1M/mFxVAJ6v+ux8BLREREVGkMvGamZHZXIhbBWsptyYiIiIgqi4HXzPxz/a5IJDLxaIiIiIhqPgZeM/NkhwYuZyAiIiIyBgZeM1MSeLlDAxEREZFxMPCamZI1vJzhJSIiIjIOBl4zU7KGlzedICIiIjIOBl4zwyUNRERERMbFwGtmeNEaERERkXEx8JqZkjW8vOkEERERkXEw8JqZ3IKS2wpzDS8RERGRMTDwmpkcxZMbTxARERFR5Zk88K5evRp+fn6wsrJCSEgIjh49+tT+CoUCs2bNgo+PD2QyGZo0aYL169drno+JiYFIJNL5KSgoqOpTMQqu4SUiIiIyLpOmqtjYWERGRmL16tXo0qULvvzyS/Tt2xdJSUlo1KhRqa8ZMmQI7t27h3Xr1qFp06bIyMhAUVGRVh97e3tcuXJFq83KyqrKzsOYuEsDERERkXGZNFUtWbIEY8eOxbhx4wAA0dHR2LdvH9asWYOFCxfq9P/ll19w+PBh3LhxAw0aNAAA+Pr66vQTiURwc3Or0rFXFV60RkRERGRcJktVhYWFiI+Px4wZM7Taw8PDcfz48VJfs2fPHoSGhmLx4sXYtGkTbG1tMWDAAHz00UewtrbW9MvNzYWPjw+Ki4vRpk0bfPTRR2jbtm2ZY1EoFFAoFJrHcrkcAKBUKqFUKitzmmUqOe6/j5/zWP3YxkJUZe9d05RVKyod62UY1kt/rJVhWC/DsF76Y63UDDl/kwXezMxMFBcXw9XVVavd1dUV6enppb7mxo0bOHbsGKysrLBr1y5kZmZiwoQJePDggWYdb0BAAGJiYtCyZUvI5XIsW7YMXbp0wblz5+Dv71/qcRcuXIh58+bptO/fvx82NjaVPNOni4uL03qcnScBIMIfJ47htnXpr6mr/l0rejrWyzCsl/5YK8OwXoZhvfRX12uVn5+vd1+RIAhCFY6lTKmpqfD09MTx48fRuXNnTfvHH3+MTZs24fLlyzqvCQ8Px9GjR5Geng4HBwcAwM6dOzF48GDk5eVpzfKWUKlUaNeuHbp3747ly5eXOpbSZni9vb2RmZkJe3v7yp5qqZRKJeLi4tC7d29IpeotyIpVAgI+VH94T854Fk62llXy3jVNabWisrFehmG99MdaGYb1MgzrpT/WSk0ul8PZ2RmPHj0qN6+ZbIbX2dkZEolEZzY3IyNDZ9a3hLu7Ozw9PTVhFwACAwMhCALu3r1b6gyuWCxG+/btce3atTLHIpPJIJPJdNqlUmmVf5D++R75j59MzdevZwWphaRK37umqY7fR23CehmG9dIfa2UY1sswrJf+6nqtDDl3k21LZmlpiZCQEJ3p+Li4OISFhZX6mi5duiA1NRW5ubmatqtXr0IsFsPLy6vU1wiCgMTERLi7uxtv8FUkp0AdeC0txJAx7BIREREZhUn34Y2KisLXX3+N9evX49KlS3jvvfeQnJyM8ePHAwBmzpyJESNGaPoPHz4cTk5OGD16NJKSknDkyBFMmzYNY8aM0SxnmDdvHvbt24cbN24gMTERY8eORWJiouaY5qxkhwY7bklGREREZDQmTVZDhw5FVlYW5s+fj7S0NAQHB2Pv3r3w8fEBAKSlpSE5OVnTv169eoiLi8OkSZMQGhoKJycnDBkyBAsWLND0yc7OxltvvaVZ59u2bVscOXIEHTp0qPbzM1QubzpBREREZHQmT1YTJkzAhAkTSn0uJiZGpy0gIOCpVyUuXboUS5cuNdbwqpXmphMMvERERERGY/JbC9MTOQreZY2IiIjI2Bh4zUjJRWt2VnX3iksiIiIiY2PgNSOaNbyc4SUiIiIyGgZeM5LDi9aIiIiIjI6B14yUbEvGi9aIiIiIjIeB14zIuYaXiIiIyOgYeM1IyRpe7tJAREREZDwMvGaEa3iJiIiIjI+B14xobi3MwEtERERkNAy8ZuRJ4OUaXiIiIiJjYeA1IyU3nuAaXiIiIiLjYeA1Izm8aI2IiIjI6Bh4zURhkQqKIhUAwJ5LGoiIiIiMhoHXTJSs3wUAW5nEhCMhIiIiql0YeM1EyfpdG0sJLCT8tRAREREZC5OVmeD6XSIiIqKqwcBrJnjTCSIiIqKqwcBrJkrW8NbjBWtERERERsXAayZK1vDac4aXiIiIyKgYeM2EZoaXa3iJiIiIjIqB10zwojUiIiKiqsHAayaeXLTGNbxERERExsTAayZyFeo1vPW4hpeIiIjIqBh4zUTJDC8vWiMiIiIyLgZeM5HLNbxEREREVYKB10xwDS8RERFR1WDgNRM5mhtPcIaXiIiIyJgYeM1EyY0neGthIiIiIuNi4DUTJTeesOMaXiIiIiKjYuA1A4IgPLnxBGd4iYiIiIyKgdcMFChVKFYJAHjRGhEREZGxMfCagZy/bzohEgE2UomJR0NERERUuzDwmoGcf+zBKxaLTDwaIiIiotqFgdcMlNx0ghesERERERkfA68Z4E0niIiIiKqOyQPv6tWr4efnBysrK4SEhODo0aNP7a9QKDBr1iz4+PhAJpOhSZMmWL9+vVafHTt2ICgoCDKZDEFBQdi1a1dVnkKl5f69hpc7NBAREREZn0kDb2xsLCIjIzFr1iwkJCSgW7du6Nu3L5KTk8t8zZAhQ3Dw4EGsW7cOV65cwdatWxEQEKB5/sSJExg6dCgiIiJw7tw5REREYMiQITh16lR1nFKFyDUzvAy8RERERMZm0oS1ZMkSjB07FuPGjQMAREdHY9++fVizZg0WLlyo0/+XX37B4cOHcePGDTRo0AAA4Ovrq9UnOjoavXv3xsyZMwEAM2fOxOHDhxEdHY2tW7dW7QlVUO4/LlojIiIiIuMyWcIqLCxEfHw8ZsyYodUeHh6O48ePl/qaPXv2IDQ0FIsXL8amTZtga2uLAQMG4KOPPoK1tTUA9Qzve++9p/W6Pn36IDo6usyxKBQKKBQKzWO5XA4AUCqVUCqVFTm9cpUcV6lUIjtf/d62lpIqe7+a7J+1ovKxXoZhvfTHWhmG9TIM66U/1krNkPM3WeDNzMxEcXExXF1dtdpdXV2Rnp5e6mtu3LiBY8eOwcrKCrt27UJmZiYmTJiABw8eaNbxpqenG3RMAFi4cCHmzZun075//37Y2NgYemoGiYuLw4VbYgBi3E9Jxt69t6r0/WqyuLg4Uw+hRmG9DMN66Y+1MgzrZRjWS391vVb5+fl69zX5d+gikfa+s4Ig6LSVUKlUEIlE2Lx5MxwcHACol0UMHjwYq1at0szyGnJMQL3sISoqSvNYLpfD29sb4eHhsLe3r9B5lUepVCIuLg69e/fG7z9dBdJS0DLQH/16NKmS96vJ/lkrqZQ7WZSH9TIM66U/1sowrJdhWC/9sVZqJd/I68NkgdfZ2RkSiURn5jUjI0NnhraEu7s7PD09NWEXAAIDAyEIAu7evQt/f3+4ubkZdEwAkMlkkMlkOu1SqbTKP0hSqRQTevhjQBsveNW3rtMf3PJUx++jNmG9DMN66Y+1MgzrZRjWS391vVaGnLvJdmmwtLRESEiIznR8XFwcwsLCSn1Nly5dkJqaitzcXE3b1atXIRaL4eXlBQDo3LmzzjH3799f5jHNga+zLbr6O8PX2dbUQyEiIiKqdUy6LVlUVBS+/vprrF+/HpcuXcJ7772H5ORkjB8/HoB6qcGIESM0/YcPHw4nJyeMHj0aSUlJOHLkCKZNm4YxY8ZoljNMmTIF+/fvx6JFi3D58mUsWrQIBw4cQGRkpClOkYiIiIhMzKRreIcOHYqsrCzMnz8faWlpCA4Oxt69e+Hj4wMASEtL09qTt169eoiLi8OkSZMQGhoKJycnDBkyBAsWLND0CQsLw7Zt2zB79mzMmTMHTZo0QWxsLDp27Fjt50dEREREpmfyi9YmTJiACRMmlPpcTEyMTltAQEC5VyUOHjwYgwcPNsbwiIiIiKiGM/mthYmIiIiIqhIDLxERERHVagy8RERERFSrMfASERERUa3GwEtEREREtRoDLxERERHVagy8RERERFSrMfASERERUa3GwEtEREREtRoDLxERERHVagy8RERERFSrWZh6AOZIEAQAgFwur7L3UCqVyM/Ph1wuh1QqrbL3qQ1YK8OwXoZhvfTHWhmG9TIM66U/1kqtJKeV5LanYeAtRU5ODgDA29vbxCMhIiIioqfJycmBg4PDU/uIBH1icR2jUqmQmpoKOzs7iESiKnkPuVwOb29v3LlzB/b29lXyHrUFa2UY1sswrJf+WCvDsF6GYb30x1qpCYKAnJwceHh4QCx++ipdzvCWQiwWw8vLq1rey97evk5/WA3BWhmG9TIM66U/1sowrJdhWC/9sVYod2a3BC9aIyIiIqJajYGXiIiIiGo1Bl4Tkclk+PDDDyGTyUw9FLPHWhmG9TIM66U/1sowrJdhWC/9sVaG40VrRERERFSrcYaXiIiIiGo1Bl4iIiIiqtUYeImIiIioVmPgJSIiIqJajYHXBFavXg0/Pz9YWVkhJCQER48eNfWQTG7hwoVo37497Ozs4OLigkGDBuHKlStafQRBwNy5c+Hh4QFra2s8++yz+PPPP000YvOycOFCiEQiREZGatpYL20pKSl444034OTkBBsbG7Rp0wbx8fGa51kvtaKiIsyePRt+fn6wtrZG48aNMX/+fKhUKk2fulyrI0eOoH///vDw8IBIJMLu3bu1ntenNgqFApMmTYKzszNsbW0xYMAA3L17txrPovo8rV5KpRLTp09Hy5YtYWtrCw8PD4wYMQKpqalax2C9Svf2229DJBIhOjpaq70u1csQDLzVLDY2FpGRkZg1axYSEhLQrVs39O3bF8nJyaYemkkdPnwY7777Lk6ePIm4uDgUFRUhPDwceXl5mj6LFy/GkiVLsHLlSpw5cwZubm7o3bs3cnJyTDhy0ztz5gzWrl2LVq1aabWzXk88fPgQXbp0gVQqxc8//4ykpCR8/vnncHR01PRhvdQWLVqEL774AitXrsSlS5ewePFifPbZZ1ixYoWmT12uVV5eHlq3bo2VK1eW+rw+tYmMjMSuXbuwbds2HDt2DLm5uXjxxRdRXFxcXadRbZ5Wr/z8fJw9exZz5szB2bNnsXPnTly9ehUDBgzQ6sd66dq9ezdOnToFDw8PnefqUr0MIlC16tChgzB+/HittoCAAGHGjBkmGpF5ysjIEAAIhw8fFgRBEFQqleDm5iZ8+umnmj4FBQWCg4OD8MUXX5hqmCaXk5Mj+Pv7C3FxccIzzzwjTJkyRRAE1uvfpk+fLnTt2rXM51mvJ1544QVhzJgxWm0vv/yy8MYbbwiCwFr9EwBh165dmsf61CY7O1uQSqXCtm3bNH1SUlIEsVgs/PLLL9U2dlP4d71Kc/r0aQGAcPv2bUEQWK/S6nX37l3B09NTuHjxouDj4yMsXbpU81xdrld5OMNbjQoLCxEfH4/w8HCt9vDwcBw/ftxEozJPjx49AgA0aNAAAHDz5k2kp6dr1U4mk+GZZ56p07V799138cILL+C5557Tame9tO3ZswehoaF49dVX4eLigrZt2+Krr77SPM96PdG1a1ccPHgQV69eBQCcO3cOx44dQ79+/QCwVk+jT23i4+OhVCq1+nh4eCA4OLjO1w9Q/9kvEok0376wXtpUKhUiIiIwbdo0tGjRQud51qtsFqYeQF2SmZmJ4uJiuLq6arW7uroiPT3dRKMyP4IgICoqCl27dkVwcDAAaOpTWu1u375d7WM0B9u2bcPZs2dx5swZnedYL203btzAmjVrEBUVhffffx+nT5/G5MmTIZPJMGLECNbrH6ZPn45Hjx4hICAAEokExcXF+PjjjzFs2DAA/Gw9jT61SU9Ph6WlJerXr6/Tp67/PVBQUIAZM2Zg+PDhsLe3B8B6/duiRYtgYWGByZMnl/o861U2Bl4TEIlEWo8FQdBpq8smTpyI8+fP49ixYzrPsXZqd+7cwZQpU7B//35YWVmV2Y/1UlOpVAgNDcUnn3wCAGjbti3+/PNPrFmzBiNGjND0Y73U1xl8++232LJlC1q0aIHExERERkbCw8MDI0eO1PRjrcpWkdrU9foplUq89tprUKlUWL16dbn962K94uPjsWzZMpw9e9bgc6+L9fo3LmmoRs7OzpBIJDr/ysrIyNCZEairJk2ahD179uDXX3+Fl5eXpt3NzQ0AWLu/xcfHIyMjAyEhIbCwsICFhQUOHz6M5cuXw8LCQlMT1kvN3d0dQUFBWm2BgYGai0X5+Xpi2rRpmDFjBl577TW0bNkSEREReO+997Bw4UIArNXT6FMbNzc3FBYW4uHDh2X2qWuUSiWGDBmCmzdvIi4uTjO7C7Be/3T06FFkZGSgUaNGmj/3b9++jalTp8LX1xcA6/U0DLzVyNLSEiEhIYiLi9Nqj4uLQ1hYmIlGZR4EQcDEiROxc+dOHDp0CH5+flrP+/n5wc3NTat2hYWFOHz4cJ2sXa9evXDhwgUkJiZqfkJDQ/H6668jMTERjRs3Zr3+oUuXLjrb3F29ehU+Pj4A+Pn6p/z8fIjF2n81SCQSzbZkrFXZ9KlNSEgIpFKpVp+0tDRcvHixTtavJOxeu3YNBw4cgJOTk9bzrNcTEREROH/+vNaf+x4eHpg2bRr27dsHgPV6KhNdLFdnbdu2TZBKpcK6deuEpKQkITIyUrC1tRVu3bpl6qGZ1DvvvCM4ODgIv/32m5CWlqb5yc/P1/T59NNPBQcHB2Hnzp3ChQsXhGHDhgnu7u6CXC434cjNxz93aRAE1uufTp8+LVhYWAgff/yxcO3aNWHz5s2CjY2N8O2332r6sF5qI0eOFDw9PYUff/xRuHnzprBz507B2dlZ+O9//6vpU5drlZOTIyQkJAgJCQkCAGHJkiVCQkKCZlcBfWozfvx4wcvLSzhw4IBw9uxZoWfPnkLr1q2FoqIiU51WlXlavZRKpTBgwADBy8tLSExM1PqzX6FQaI7Bej35fP3bv3dpEIS6VS9DMPCawKpVqwQfHx/B0tJSaNeunWbrrboMQKk/GzZs0PRRqVTChx9+KLi5uQkymUzo3r27cOHCBdMN2sz8O/CyXtp++OEHITg4WJDJZEJAQICwdu1aredZLzW5XC5MmTJFaNSokWBlZSU0btxYmDVrllYAqcu1+vXXX0v9s2rkyJGCIOhXm8ePHwsTJ04UGjRoIFhbWwsvvviikJycbIKzqXpPq9fNmzfL/LP/119/1RyD9Xry+fq30gJvXaqXIUSCIAjVMZNMRERERGQKXMNLRERERLUaAy8RERER1WoMvERERERUqzHwEhEREVGtxsBLRERERLUaAy8RERER1WoMvERERERUqzHwEhEREVGtxsBLRERlEolE2L17t6mHQURUKQy8RERmatSoURCJRDo/zz//vKmHRkRUo1iYegBERFS2559/Hhs2bNBqk8lkJhoNEVHNxBleIiIzJpPJ4ObmpvVTv359AOrlBmvWrEHfvn1hbW0NPz8/bN++Xev1Fy5cQM+ePWFtbQ0nJye89dZbyM3N1eqzfv16tGjRAjKZDO7u7pg4caLW85mZmXjppZdgY2MDf39/7Nmzp2pPmojIyBh4iYhqsDlz5uCVV17BuXPn8MYbb2DYsGG4dOkSACA/Px/PP/886tevjzNnzmD79u04cOCAVqBds2YN3n33Xbz11lu4cOEC9uzZg6ZNm2q9x7x58zBkyBCcP38e/fr1w+uvv44HDx5U63kSEVWGSBAEwdSDICIiXaNGjcK3334LKysrrfbp06djzpw5EIlEGD9+PNasWaN5rlOnTmjXrh1Wr16Nr776CtOnT8edO3dga2sLANi7dy/69++P1NRUuLq6wtPTE6NHj8aCBQtKHYNIJMLs2bPx0UcfAQDy8vJgZ2eHvXv3ci0xEdUYXMNLRGTGevTooRVoAaBBgwaa/+7cubPWc507d0ZiYiIA4NKlS2jdurUm7AJAly5doFKpcOXKFYhEIqSmpqJXr15PHUOrVq00/21raws7OztkZGRU9JSIiKodAy8RkRmztbXVWWJQHpFIBAAQBEHz36X1sba21ut4UqlU57UqlcqgMRERmRLX8BIR1WAnT57UeRwQEAAACAoKQmJiIvLy8jTP//777xCLxWjWrBns7Ozg6+uLgwcPVuuYiYiqG2d4iYjMmEKhQHp6ulabhYUFnJ2dAQDbt29HaGgounbtis2bN+P06dNYt24dAOD111/Hhx9+iJEjR2Lu3Lm4f/8+Jk2ahIiICLi6ugIA5s6di/Hjx8PFxQV9+/ZFTk4Ofv/9d0yaNKl6T5SIqAox8BIRmbFffvkF7u7uWm3NmzfH5cuXAah3UNi2bRsmTJgANzc3bN68GUFBQQAAGxsb7Nu3D1OmTEH79u1hY2ODV155BUuWLNEca+TIkSgoKMDSpUvxn//8B87Ozhg8eHD1nSARUTXgLg1ERDWUSCTCrl27MGjQIFMPhYjIrHENLxERERHVagy8RERERFSrcQ0vEVENxRVpRET64QwvEREREdVqDLxEREREVKsx8BIRERFRrcbAS0RERES1GgMvEREREdVqDLxEREREVKsx8BIRERFRrcbAS0RERES12v8DlxJQJldazgUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracy of the model\n",
    "plot_df = pd.DataFrame(history.history, index =  range(1, len(history.history[\"loss\"]) + 1))\n",
    "plot_df.plot(y = \"accuracy\", figsize = (8, 5))\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"model_accuracy_opt.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inclassfeb2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
