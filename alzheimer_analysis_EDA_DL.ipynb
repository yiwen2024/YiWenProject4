{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import regularizers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholConsumption</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>...</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>ADL</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Disorientation</th>\n",
       "      <th>PersonalityChanges</th>\n",
       "      <th>DifficultyCompletingTasks</th>\n",
       "      <th>Forgetfulness</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>DoctorInCharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4751</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.927749</td>\n",
       "      <td>0</td>\n",
       "      <td>13.297218</td>\n",
       "      <td>6.327112</td>\n",
       "      <td>1.347214</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.725883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4752</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.827681</td>\n",
       "      <td>0</td>\n",
       "      <td>4.542524</td>\n",
       "      <td>7.619885</td>\n",
       "      <td>0.518767</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.592424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4753</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17.795882</td>\n",
       "      <td>0</td>\n",
       "      <td>19.555085</td>\n",
       "      <td>7.844988</td>\n",
       "      <td>1.826335</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.119548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4754</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.800817</td>\n",
       "      <td>1</td>\n",
       "      <td>12.209266</td>\n",
       "      <td>8.428001</td>\n",
       "      <td>7.435604</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.481226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4755</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.716974</td>\n",
       "      <td>0</td>\n",
       "      <td>18.454356</td>\n",
       "      <td>6.310461</td>\n",
       "      <td>0.795498</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  Age  Gender  Ethnicity  EducationLevel        BMI  Smoking  \\\n",
       "0       4751   73       0          0               2  22.927749        0   \n",
       "1       4752   89       0          0               0  26.827681        0   \n",
       "2       4753   73       0          3               1  17.795882        0   \n",
       "3       4754   74       1          0               1  33.800817        1   \n",
       "4       4755   89       0          0               0  20.716974        0   \n",
       "\n",
       "   AlcoholConsumption  PhysicalActivity  DietQuality  ...  MemoryComplaints  \\\n",
       "0           13.297218          6.327112     1.347214  ...                 0   \n",
       "1            4.542524          7.619885     0.518767  ...                 0   \n",
       "2           19.555085          7.844988     1.826335  ...                 0   \n",
       "3           12.209266          8.428001     7.435604  ...                 0   \n",
       "4           18.454356          6.310461     0.795498  ...                 0   \n",
       "\n",
       "   BehavioralProblems       ADL  Confusion  Disorientation  \\\n",
       "0                   0  1.725883          0               0   \n",
       "1                   0  2.592424          0               0   \n",
       "2                   0  7.119548          0               1   \n",
       "3                   1  6.481226          0               0   \n",
       "4                   0  0.014691          0               0   \n",
       "\n",
       "   PersonalityChanges  DifficultyCompletingTasks  Forgetfulness  Diagnosis  \\\n",
       "0                   0                          1              0          0   \n",
       "1                   0                          0              1          0   \n",
       "2                   0                          1              0          0   \n",
       "3                   0                          0              0          0   \n",
       "4                   1                          1              0          0   \n",
       "\n",
       "   DoctorInCharge  \n",
       "0       XXXConfid  \n",
       "1       XXXConfid  \n",
       "2       XXXConfid  \n",
       "3       XXXConfid  \n",
       "4       XXXConfid  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame for the healthcare-dataset-stroke-data.csv. \n",
    "file_path = Path(\"Resources/alzheimers_disease_data.csv\")\n",
    "alzheimer_df = pd.read_csv(file_path)\n",
    "alzheimer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data cleaning and preparation process \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total rows: 2149\n",
      "Number of total columns: 35\n"
     ]
    }
   ],
   "source": [
    "# determine the number of rows and columns.\n",
    "alzheimer_df_rc, alzheimer_df_cc = alzheimer_df.shape\n",
    "print('Number of total rows:', alzheimer_df_rc)\n",
    "print('Number of total columns:', alzheimer_df_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PatientID', 'Age', 'Gender', 'Ethnicity', 'EducationLevel', 'BMI',\n",
       "       'Smoking', 'AlcoholConsumption', 'PhysicalActivity', 'DietQuality',\n",
       "       'SleepQuality', 'FamilyHistoryAlzheimers', 'CardiovascularDisease',\n",
       "       'Diabetes', 'Depression', 'HeadInjury', 'Hypertension', 'SystolicBP',\n",
       "       'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL', 'CholesterolHDL',\n",
       "       'CholesterolTriglycerides', 'MMSE', 'FunctionalAssessment',\n",
       "       'MemoryComplaints', 'BehavioralProblems', 'ADL', 'Confusion',\n",
       "       'Disorientation', 'PersonalityChanges', 'DifficultyCompletingTasks',\n",
       "       'Forgetfulness', 'Diagnosis', 'DoctorInCharge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all columns inside of the DataFrame\n",
    "alzheimer_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show duplicates\n",
    "duplicate = alzheimer_df[alzheimer_df.duplicated()]\n",
    "print(\"Duplicate Rows:\", len(duplicate), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatientID                    0\n",
       "Age                          0\n",
       "Gender                       0\n",
       "Ethnicity                    0\n",
       "EducationLevel               0\n",
       "BMI                          0\n",
       "Smoking                      0\n",
       "AlcoholConsumption           0\n",
       "PhysicalActivity             0\n",
       "DietQuality                  0\n",
       "SleepQuality                 0\n",
       "FamilyHistoryAlzheimers      0\n",
       "CardiovascularDisease        0\n",
       "Diabetes                     0\n",
       "Depression                   0\n",
       "HeadInjury                   0\n",
       "Hypertension                 0\n",
       "SystolicBP                   0\n",
       "DiastolicBP                  0\n",
       "CholesterolTotal             0\n",
       "CholesterolLDL               0\n",
       "CholesterolHDL               0\n",
       "CholesterolTriglycerides     0\n",
       "MMSE                         0\n",
       "FunctionalAssessment         0\n",
       "MemoryComplaints             0\n",
       "BehavioralProblems           0\n",
       "ADL                          0\n",
       "Confusion                    0\n",
       "Disorientation               0\n",
       "PersonalityChanges           0\n",
       "DifficultyCompletingTasks    0\n",
       "Forgetfulness                0\n",
       "Diagnosis                    0\n",
       "DoctorInCharge               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "alzheimer_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with missing information \n",
    "alzheimer_df = alzheimer_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatientID 2149\n",
      "Age 31\n",
      "Gender 2\n",
      "Ethnicity 4\n",
      "EducationLevel 4\n",
      "BMI 2149\n",
      "Smoking 2\n",
      "AlcoholConsumption 2149\n",
      "PhysicalActivity 2149\n",
      "DietQuality 2149\n",
      "SleepQuality 2149\n",
      "FamilyHistoryAlzheimers 2\n",
      "CardiovascularDisease 2\n",
      "Diabetes 2\n",
      "Depression 2\n",
      "HeadInjury 2\n",
      "Hypertension 2\n",
      "SystolicBP 90\n",
      "DiastolicBP 60\n",
      "CholesterolTotal 2149\n",
      "CholesterolLDL 2149\n",
      "CholesterolHDL 2149\n",
      "CholesterolTriglycerides 2149\n",
      "MMSE 2149\n",
      "FunctionalAssessment 2149\n",
      "MemoryComplaints 2\n",
      "BehavioralProblems 2\n",
      "ADL 2149\n",
      "Confusion 2\n",
      "Disorientation 2\n",
      "PersonalityChanges 2\n",
      "DifficultyCompletingTasks 2\n",
      "Forgetfulness 2\n",
      "Diagnosis 2\n",
      "DoctorInCharge 1\n"
     ]
    }
   ],
   "source": [
    "# print out columns and number of unique values\n",
    "for col in alzheimer_df.columns:\n",
    "    print(col, alzheimer_df[col].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exploratory Data Analysis (EDA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "0    1389\n",
       "1     760\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the stroke outcome value counts\n",
    "alzheimer_counts = alzheimer_df['Diagnosis'].value_counts()\n",
    "alzheimer_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>FunctionalAssessment</th>\n",
       "      <th>ADL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.463532</td>\n",
       "      <td>6.518877</td>\n",
       "      <td>1.725883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.613267</td>\n",
       "      <td>7.118696</td>\n",
       "      <td>2.592424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.356249</td>\n",
       "      <td>5.895077</td>\n",
       "      <td>7.119548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.991127</td>\n",
       "      <td>8.965106</td>\n",
       "      <td>6.481226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.517609</td>\n",
       "      <td>6.045039</td>\n",
       "      <td>0.014691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.201190</td>\n",
       "      <td>0.238667</td>\n",
       "      <td>4.492838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.458060</td>\n",
       "      <td>8.687480</td>\n",
       "      <td>9.204952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.011003</td>\n",
       "      <td>1.972137</td>\n",
       "      <td>5.036334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.030491</td>\n",
       "      <td>5.173891</td>\n",
       "      <td>3.785399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.114777</td>\n",
       "      <td>6.307543</td>\n",
       "      <td>8.327563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2149 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ethnicity  Gender  Age  EducationLevel  Diagnosis  MemoryComplaints  \\\n",
       "0             0       0   73               2          0                 0   \n",
       "1             0       0   89               0          0                 0   \n",
       "2             3       0   73               1          0                 0   \n",
       "3             0       1   74               1          0                 0   \n",
       "4             0       0   89               0          0                 0   \n",
       "...         ...     ...  ...             ...        ...               ...   \n",
       "2144          0       0   61               1          1                 0   \n",
       "2145          0       0   75               2          1                 0   \n",
       "2146          0       0   77               1          1                 0   \n",
       "2147          3       1   78               1          1                 0   \n",
       "2148          0       0   72               2          0                 0   \n",
       "\n",
       "      BehavioralProblems       MMSE  FunctionalAssessment       ADL  \n",
       "0                      0  21.463532              6.518877  1.725883  \n",
       "1                      0  20.613267              7.118696  2.592424  \n",
       "2                      0   7.356249              5.895077  7.119548  \n",
       "3                      1  13.991127              8.965106  6.481226  \n",
       "4                      0  13.517609              6.045039  0.014691  \n",
       "...                  ...        ...                   ...       ...  \n",
       "2144                   0   1.201190              0.238667  4.492838  \n",
       "2145                   1   6.458060              8.687480  9.204952  \n",
       "2146                   0  17.011003              1.972137  5.036334  \n",
       "2147                   0   4.030491              5.173891  3.785399  \n",
       "2148                   1  11.114777              6.307543  8.327563  \n",
       "\n",
       "[2149 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep part of columns for abalysis\n",
    "alzheimer_cleanML_df = alzheimer_df[['Ethnicity', 'Gender', 'Age', 'EducationLevel', 'Diagnosis', 'MemoryComplaints','BehavioralProblems', 'MMSE', 'FunctionalAssessment','ADL']]\n",
    "alzheimer_cleanML_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age: The age of the patients ranges from 60 to 90 years.\n",
    "**Gender: Gender of the patients, where 0 represents Male and 1 represents Female.\n",
    "**Ethnicity: The ethnicity of the patients, coded as follows:\n",
    "0: Caucasian\n",
    "1: African American\n",
    "2: Asian\n",
    "3: Other\n",
    "**EducationLevel: The education level of the patients, coded as follows:\n",
    "0: None\n",
    "1: High School\n",
    "2: Bachelor's\n",
    "3: Higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>FunctionalAssessment</th>\n",
       "      <th>ADL</th>\n",
       "      <th>Caucasian</th>\n",
       "      <th>African American</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Other</th>\n",
       "      <th>None</th>\n",
       "      <th>High School</th>\n",
       "      <th>Bachelor's</th>\n",
       "      <th>Higher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.463532</td>\n",
       "      <td>6.518877</td>\n",
       "      <td>1.725883</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.613267</td>\n",
       "      <td>7.118696</td>\n",
       "      <td>2.592424</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.356249</td>\n",
       "      <td>5.895077</td>\n",
       "      <td>7.119548</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.991127</td>\n",
       "      <td>8.965106</td>\n",
       "      <td>6.481226</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.517609</td>\n",
       "      <td>6.045039</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.201190</td>\n",
       "      <td>0.238667</td>\n",
       "      <td>4.492838</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.458060</td>\n",
       "      <td>8.687480</td>\n",
       "      <td>9.204952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.011003</td>\n",
       "      <td>1.972137</td>\n",
       "      <td>5.036334</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.030491</td>\n",
       "      <td>5.173891</td>\n",
       "      <td>3.785399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.114777</td>\n",
       "      <td>6.307543</td>\n",
       "      <td>8.327563</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2149 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Age  Diagnosis  MemoryComplaints  BehavioralProblems       MMSE  \\\n",
       "0          0   73          0                 0                   0  21.463532   \n",
       "1          0   89          0                 0                   0  20.613267   \n",
       "2          0   73          0                 0                   0   7.356249   \n",
       "3          1   74          0                 0                   1  13.991127   \n",
       "4          0   89          0                 0                   0  13.517609   \n",
       "...      ...  ...        ...               ...                 ...        ...   \n",
       "2144       0   61          1                 0                   0   1.201190   \n",
       "2145       0   75          1                 0                   1   6.458060   \n",
       "2146       0   77          1                 0                   0  17.011003   \n",
       "2147       1   78          1                 0                   0   4.030491   \n",
       "2148       0   72          0                 0                   1  11.114777   \n",
       "\n",
       "      FunctionalAssessment       ADL  Caucasian  African American  Asian  \\\n",
       "0                 6.518877  1.725883          1                 0      0   \n",
       "1                 7.118696  2.592424          1                 0      0   \n",
       "2                 5.895077  7.119548          0                 0      0   \n",
       "3                 8.965106  6.481226          1                 0      0   \n",
       "4                 6.045039  0.014691          1                 0      0   \n",
       "...                    ...       ...        ...               ...    ...   \n",
       "2144              0.238667  4.492838          1                 0      0   \n",
       "2145              8.687480  9.204952          1                 0      0   \n",
       "2146              1.972137  5.036334          1                 0      0   \n",
       "2147              5.173891  3.785399          0                 0      0   \n",
       "2148              6.307543  8.327563          1                 0      0   \n",
       "\n",
       "      Other  None  High School  Bachelor's  Higher  \n",
       "0         0     0            0           1       0  \n",
       "1         0     1            0           0       0  \n",
       "2         1     0            1           0       0  \n",
       "3         0     0            1           0       0  \n",
       "4         0     1            0           0       0  \n",
       "...     ...   ...          ...         ...     ...  \n",
       "2144      0     0            1           0       0  \n",
       "2145      0     0            0           1       0  \n",
       "2146      0     0            1           0       0  \n",
       "2147      1     0            1           0       0  \n",
       "2148      0     0            0           1       0  \n",
       "\n",
       "[2149 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new columns for each ethnicity and education level to obtain binary values\n",
    "alzheimer_cleanML_df['Caucasian'] = (alzheimer_cleanML_df['Ethnicity'] == 0).astype(int)\n",
    "alzheimer_cleanML_df['African American'] = (alzheimer_cleanML_df['Ethnicity'] == 1).astype(int)\n",
    "alzheimer_cleanML_df['Asian'] = (alzheimer_cleanML_df['Ethnicity'] == 2).astype(int)\n",
    "alzheimer_cleanML_df['Other'] = (alzheimer_cleanML_df['Ethnicity'] == 3).astype(int)\n",
    "\n",
    "alzheimer_cleanML_df['None'] = (alzheimer_cleanML_df['EducationLevel'] == 0).astype(int)\n",
    "alzheimer_cleanML_df['High School'] = (alzheimer_cleanML_df['EducationLevel'] == 1).astype(int)\n",
    "alzheimer_cleanML_df['Bachelor\\'s'] = (alzheimer_cleanML_df['EducationLevel'] == 2).astype(int)\n",
    "alzheimer_cleanML_df['Higher'] = (alzheimer_cleanML_df['EducationLevel'] == 3).astype(int)\n",
    "\n",
    "# Drop the original Ethnicity and EducationLevel columns\n",
    "alzheimer_cleanML_df = alzheimer_cleanML_df.drop('Ethnicity', axis=1)\n",
    "alzheimer_cleanML_df = alzheimer_cleanML_df.drop('EducationLevel', axis=1)\n",
    "\n",
    "# Display the first few rows of the reshaped dataframe\n",
    "alzheimer_cleanML_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data:\n",
    "X = alzheimer_cleanML_df.drop('Diagnosis', axis=1)  \n",
    "y = alzheimer_cleanML_df['Diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# Review number of features\n",
    "print(len(X_train_scaled[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(8, activation='sigmoid'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,777</span> (14.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,777\u001b[0m (14.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,777</span> (14.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,777\u001b[0m (14.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4288 - loss: 0.7341 - val_accuracy: 0.6570 - val_loss: 0.6177\n",
      "Epoch 2/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7266 - loss: 0.5761 - val_accuracy: 0.7733 - val_loss: 0.5140\n",
      "Epoch 3/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.4608 - val_accuracy: 0.7762 - val_loss: 0.4568\n",
      "Epoch 4/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.3607 - val_accuracy: 0.7994 - val_loss: 0.4226\n",
      "Epoch 5/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8612 - loss: 0.3589 - val_accuracy: 0.8285 - val_loss: 0.3993\n",
      "Epoch 6/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8718 - loss: 0.3379 - val_accuracy: 0.8023 - val_loss: 0.4133\n",
      "Epoch 7/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8849 - loss: 0.3260 - val_accuracy: 0.8285 - val_loss: 0.3946\n",
      "Epoch 8/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8773 - loss: 0.3253 - val_accuracy: 0.8401 - val_loss: 0.3815\n",
      "Epoch 9/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8935 - loss: 0.2886 - val_accuracy: 0.8343 - val_loss: 0.3848\n",
      "Epoch 10/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8957 - loss: 0.2863 - val_accuracy: 0.8372 - val_loss: 0.3837\n",
      "Epoch 11/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8997 - loss: 0.2955 - val_accuracy: 0.8430 - val_loss: 0.3790\n",
      "Epoch 12/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8996 - loss: 0.2688 - val_accuracy: 0.8430 - val_loss: 0.3787\n",
      "Epoch 13/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9025 - loss: 0.2677 - val_accuracy: 0.8401 - val_loss: 0.3829\n",
      "Epoch 14/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9196 - loss: 0.2504 - val_accuracy: 0.8314 - val_loss: 0.3801\n",
      "Epoch 15/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9319 - loss: 0.2333 - val_accuracy: 0.8430 - val_loss: 0.3851\n",
      "Epoch 16/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8927 - loss: 0.2698 - val_accuracy: 0.8459 - val_loss: 0.3761\n",
      "Epoch 17/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2625 - val_accuracy: 0.8401 - val_loss: 0.3788\n",
      "Epoch 18/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9329 - loss: 0.2175 - val_accuracy: 0.8430 - val_loss: 0.3861\n",
      "Epoch 19/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9309 - loss: 0.2307 - val_accuracy: 0.8488 - val_loss: 0.3809\n",
      "Epoch 20/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9348 - loss: 0.2178 - val_accuracy: 0.8401 - val_loss: 0.3879\n",
      "Epoch 21/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9327 - loss: 0.2039 - val_accuracy: 0.8488 - val_loss: 0.3861\n",
      "Epoch 22/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.1830 - val_accuracy: 0.8430 - val_loss: 0.3843\n",
      "Epoch 23/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.2138 - val_accuracy: 0.8430 - val_loss: 0.3870\n",
      "Epoch 24/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.2100 - val_accuracy: 0.8372 - val_loss: 0.4000\n",
      "Epoch 25/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9361 - loss: 0.2152 - val_accuracy: 0.8430 - val_loss: 0.3869\n",
      "Epoch 26/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9456 - loss: 0.1844 - val_accuracy: 0.8459 - val_loss: 0.3923\n",
      "Epoch 27/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.1825 - val_accuracy: 0.8372 - val_loss: 0.3907\n",
      "Epoch 28/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9379 - loss: 0.1893 - val_accuracy: 0.8488 - val_loss: 0.3981\n",
      "Epoch 29/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9448 - loss: 0.1855 - val_accuracy: 0.8459 - val_loss: 0.3929\n",
      "Epoch 30/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9430 - loss: 0.1984 - val_accuracy: 0.8430 - val_loss: 0.4012\n",
      "Epoch 31/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9558 - loss: 0.1619 - val_accuracy: 0.8372 - val_loss: 0.3960\n",
      "Epoch 32/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1603 - val_accuracy: 0.8459 - val_loss: 0.4035\n",
      "Epoch 33/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9578 - loss: 0.1681 - val_accuracy: 0.8401 - val_loss: 0.4080\n",
      "Epoch 34/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.1574 - val_accuracy: 0.8372 - val_loss: 0.4282\n",
      "Epoch 35/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.1681 - val_accuracy: 0.8314 - val_loss: 0.4278\n",
      "Epoch 36/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.1502 - val_accuracy: 0.8169 - val_loss: 0.4473\n",
      "Epoch 37/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9605 - loss: 0.1541 - val_accuracy: 0.8256 - val_loss: 0.4373\n",
      "Epoch 38/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9577 - loss: 0.1535 - val_accuracy: 0.8488 - val_loss: 0.4224\n",
      "Epoch 39/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9699 - loss: 0.1276 - val_accuracy: 0.8372 - val_loss: 0.4370\n",
      "Epoch 40/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9648 - loss: 0.1412 - val_accuracy: 0.8343 - val_loss: 0.4530\n",
      "Epoch 41/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9655 - loss: 0.1209 - val_accuracy: 0.8401 - val_loss: 0.4472\n",
      "Epoch 42/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9630 - loss: 0.1459 - val_accuracy: 0.8314 - val_loss: 0.4600\n",
      "Epoch 43/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9671 - loss: 0.1345 - val_accuracy: 0.8285 - val_loss: 0.4656\n",
      "Epoch 44/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9764 - loss: 0.1056 - val_accuracy: 0.8314 - val_loss: 0.4643\n",
      "Epoch 45/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9682 - loss: 0.1154 - val_accuracy: 0.8314 - val_loss: 0.4722\n",
      "Epoch 46/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9655 - loss: 0.1385 - val_accuracy: 0.8227 - val_loss: 0.4726\n",
      "Epoch 47/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.1066 - val_accuracy: 0.8314 - val_loss: 0.4594\n",
      "Epoch 48/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9732 - loss: 0.1195 - val_accuracy: 0.8401 - val_loss: 0.4586\n",
      "Epoch 49/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.1117 - val_accuracy: 0.8372 - val_loss: 0.4692\n",
      "Epoch 50/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9730 - loss: 0.1311 - val_accuracy: 0.8401 - val_loss: 0.4689\n",
      "Epoch 51/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9723 - loss: 0.1362 - val_accuracy: 0.8285 - val_loss: 0.4801\n",
      "Epoch 52/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9789 - loss: 0.1071 - val_accuracy: 0.8314 - val_loss: 0.5022\n",
      "Epoch 53/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.1139 - val_accuracy: 0.8343 - val_loss: 0.4900\n",
      "Epoch 54/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9755 - loss: 0.1119 - val_accuracy: 0.8372 - val_loss: 0.4737\n",
      "Epoch 55/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.1079 - val_accuracy: 0.8343 - val_loss: 0.4716\n",
      "Epoch 56/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9723 - loss: 0.1197 - val_accuracy: 0.8401 - val_loss: 0.4926\n",
      "Epoch 57/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0971 - val_accuracy: 0.8256 - val_loss: 0.5092\n",
      "Epoch 58/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9778 - loss: 0.1110 - val_accuracy: 0.8459 - val_loss: 0.4646\n",
      "Epoch 59/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9757 - loss: 0.1089 - val_accuracy: 0.8401 - val_loss: 0.4992\n",
      "Epoch 60/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0992 - val_accuracy: 0.8227 - val_loss: 0.5022\n",
      "Epoch 61/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.1105 - val_accuracy: 0.8372 - val_loss: 0.5369\n",
      "Epoch 62/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.0897 - val_accuracy: 0.8401 - val_loss: 0.4918\n",
      "Epoch 63/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9781 - loss: 0.1110 - val_accuracy: 0.8488 - val_loss: 0.4921\n",
      "Epoch 64/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9813 - loss: 0.0967 - val_accuracy: 0.8285 - val_loss: 0.5279\n",
      "Epoch 65/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0657 - val_accuracy: 0.8343 - val_loss: 0.5044\n",
      "Epoch 66/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 0.1269 - val_accuracy: 0.8285 - val_loss: 0.5508\n",
      "Epoch 67/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9729 - loss: 0.1076 - val_accuracy: 0.8256 - val_loss: 0.5733\n",
      "Epoch 68/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0993 - val_accuracy: 0.8372 - val_loss: 0.5134\n",
      "Epoch 69/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.1049 - val_accuracy: 0.8488 - val_loss: 0.5150\n",
      "Epoch 70/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9782 - loss: 0.0939 - val_accuracy: 0.8285 - val_loss: 0.5261\n",
      "Epoch 71/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9742 - loss: 0.1050 - val_accuracy: 0.8459 - val_loss: 0.5326\n",
      "Epoch 72/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.1159 - val_accuracy: 0.8430 - val_loss: 0.5262\n",
      "Epoch 73/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9830 - loss: 0.0796 - val_accuracy: 0.8314 - val_loss: 0.5093\n",
      "Epoch 74/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9737 - loss: 0.1134 - val_accuracy: 0.8430 - val_loss: 0.5240\n",
      "Epoch 75/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0771 - val_accuracy: 0.8256 - val_loss: 0.5407\n",
      "Epoch 76/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0727 - val_accuracy: 0.8372 - val_loss: 0.5318\n",
      "Epoch 77/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.0893 - val_accuracy: 0.8314 - val_loss: 0.5629\n",
      "Epoch 78/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.0915 - val_accuracy: 0.8227 - val_loss: 0.5547\n",
      "Epoch 79/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0929 - val_accuracy: 0.8343 - val_loss: 0.5557\n",
      "Epoch 80/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.1062 - val_accuracy: 0.8372 - val_loss: 0.5624\n",
      "Epoch 81/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0725 - val_accuracy: 0.8343 - val_loss: 0.5684\n",
      "Epoch 82/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0941 - val_accuracy: 0.8343 - val_loss: 0.5585\n",
      "Epoch 83/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9865 - loss: 0.0716 - val_accuracy: 0.8227 - val_loss: 0.5788\n",
      "Epoch 84/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9712 - loss: 0.1271 - val_accuracy: 0.8314 - val_loss: 0.5777\n",
      "Epoch 85/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0931 - val_accuracy: 0.8343 - val_loss: 0.5597\n",
      "Epoch 86/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0791 - val_accuracy: 0.8372 - val_loss: 0.5724\n",
      "Epoch 87/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.1003 - val_accuracy: 0.8314 - val_loss: 0.5801\n",
      "Epoch 88/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0699 - val_accuracy: 0.8256 - val_loss: 0.5920\n",
      "Epoch 89/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9759 - loss: 0.1182 - val_accuracy: 0.8401 - val_loss: 0.5612\n",
      "Epoch 90/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.0804 - val_accuracy: 0.8343 - val_loss: 0.5809\n",
      "Epoch 91/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0587 - val_accuracy: 0.8285 - val_loss: 0.5802\n",
      "Epoch 92/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0678 - val_accuracy: 0.8343 - val_loss: 0.5786\n",
      "Epoch 93/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0867 - val_accuracy: 0.8314 - val_loss: 0.5731\n",
      "Epoch 94/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0898 - val_accuracy: 0.8430 - val_loss: 0.5814\n",
      "Epoch 95/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0831 - val_accuracy: 0.8256 - val_loss: 0.6486\n",
      "Epoch 96/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9691 - loss: 0.1211 - val_accuracy: 0.8517 - val_loss: 0.5790\n",
      "Epoch 97/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9655 - loss: 0.1331 - val_accuracy: 0.8169 - val_loss: 0.6351\n",
      "Epoch 98/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.1045 - val_accuracy: 0.8343 - val_loss: 0.5644\n",
      "Epoch 99/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9811 - loss: 0.0733 - val_accuracy: 0.8314 - val_loss: 0.5603\n",
      "Epoch 100/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.1044 - val_accuracy: 0.8314 - val_loss: 0.5872\n",
      "Epoch 101/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0816 - val_accuracy: 0.8343 - val_loss: 0.5712\n",
      "Epoch 102/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.0880 - val_accuracy: 0.8372 - val_loss: 0.5940\n",
      "Epoch 103/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0708 - val_accuracy: 0.8372 - val_loss: 0.5819\n",
      "Epoch 104/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0693 - val_accuracy: 0.8372 - val_loss: 0.5881\n",
      "Epoch 105/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0613 - val_accuracy: 0.8343 - val_loss: 0.5900\n",
      "Epoch 106/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0835 - val_accuracy: 0.8314 - val_loss: 0.5962\n",
      "Epoch 107/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0973 - val_accuracy: 0.8343 - val_loss: 0.5895\n",
      "Epoch 108/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0790 - val_accuracy: 0.8343 - val_loss: 0.5946\n",
      "Epoch 109/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.0933 - val_accuracy: 0.8372 - val_loss: 0.5937\n",
      "Epoch 110/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0858 - val_accuracy: 0.8343 - val_loss: 0.5958\n",
      "Epoch 111/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0853 - val_accuracy: 0.8372 - val_loss: 0.6018\n",
      "Epoch 112/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0724 - val_accuracy: 0.8343 - val_loss: 0.6041\n",
      "Epoch 113/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.0881 - val_accuracy: 0.8372 - val_loss: 0.6017\n",
      "Epoch 114/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0853 - val_accuracy: 0.8343 - val_loss: 0.6069\n",
      "Epoch 115/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.0750 - val_accuracy: 0.8343 - val_loss: 0.6071\n",
      "Epoch 116/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9830 - loss: 0.0861 - val_accuracy: 0.8343 - val_loss: 0.6065\n",
      "Epoch 117/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9830 - loss: 0.0902 - val_accuracy: 0.8314 - val_loss: 0.6105\n",
      "Epoch 118/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0741 - val_accuracy: 0.8314 - val_loss: 0.6129\n",
      "Epoch 119/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9865 - loss: 0.0712 - val_accuracy: 0.8314 - val_loss: 0.6074\n",
      "Epoch 120/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0812 - val_accuracy: 0.8314 - val_loss: 0.6048\n",
      "Epoch 121/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 0.0919 - val_accuracy: 0.8430 - val_loss: 0.5857\n",
      "Epoch 122/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9721 - loss: 0.1264 - val_accuracy: 0.8314 - val_loss: 0.6161\n",
      "Epoch 123/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9823 - loss: 0.0798 - val_accuracy: 0.8198 - val_loss: 0.6629\n",
      "Epoch 124/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.1307 - val_accuracy: 0.8401 - val_loss: 0.5839\n",
      "Epoch 125/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.1009 - val_accuracy: 0.8401 - val_loss: 0.5922\n",
      "Epoch 126/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.1002 - val_accuracy: 0.8459 - val_loss: 0.5995\n",
      "Epoch 127/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9799 - loss: 0.0947 - val_accuracy: 0.8285 - val_loss: 0.6395\n",
      "Epoch 128/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0808 - val_accuracy: 0.8285 - val_loss: 0.6490\n",
      "Epoch 129/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0803 - val_accuracy: 0.8343 - val_loss: 0.6275\n",
      "Epoch 130/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0741 - val_accuracy: 0.8285 - val_loss: 0.6406\n",
      "Epoch 131/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0682 - val_accuracy: 0.8343 - val_loss: 0.6227\n",
      "Epoch 132/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9782 - loss: 0.0889 - val_accuracy: 0.8343 - val_loss: 0.6010\n",
      "Epoch 133/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9878 - loss: 0.0678 - val_accuracy: 0.8343 - val_loss: 0.6158\n",
      "Epoch 134/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0756 - val_accuracy: 0.8314 - val_loss: 0.6246\n",
      "Epoch 135/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9772 - loss: 0.1049 - val_accuracy: 0.8343 - val_loss: 0.6226\n",
      "Epoch 136/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0750 - val_accuracy: 0.8343 - val_loss: 0.6189\n",
      "Epoch 137/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0643 - val_accuracy: 0.8343 - val_loss: 0.6412\n",
      "Epoch 138/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9888 - loss: 0.0598 - val_accuracy: 0.8372 - val_loss: 0.6144\n",
      "Epoch 139/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0892 - val_accuracy: 0.8285 - val_loss: 0.6472\n",
      "Epoch 140/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0689 - val_accuracy: 0.8314 - val_loss: 0.6399\n",
      "Epoch 141/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0798 - val_accuracy: 0.8372 - val_loss: 0.6239\n",
      "Epoch 142/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9836 - loss: 0.0780 - val_accuracy: 0.8372 - val_loss: 0.6138\n",
      "Epoch 143/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.1011 - val_accuracy: 0.8372 - val_loss: 0.6178\n",
      "Epoch 144/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.0902 - val_accuracy: 0.8430 - val_loss: 0.6026\n",
      "Epoch 145/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9808 - loss: 0.0923 - val_accuracy: 0.8314 - val_loss: 0.6104\n",
      "Epoch 146/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0796 - val_accuracy: 0.8314 - val_loss: 0.6245\n",
      "Epoch 147/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.1312 - val_accuracy: 0.8285 - val_loss: 0.6114\n",
      "Epoch 148/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9763 - loss: 0.1090 - val_accuracy: 0.8285 - val_loss: 0.6021\n",
      "Epoch 149/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.1193 - val_accuracy: 0.8343 - val_loss: 0.6107\n",
      "Epoch 150/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9755 - loss: 0.1101 - val_accuracy: 0.8285 - val_loss: 0.6209\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=150, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.8909 - loss: 0.4005\n",
      "Test accuracy: 0.8744186162948608\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "filename = 'alzheimer_ML.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracy of the model\n",
    "plot_df = pd.DataFrame(history.history, index =  range(1, len(history.history[\"loss\"]) + 1))\n",
    "plot_df.plot(y = \"accuracy\", figsize = (8, 5))\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"model_accuracy_opt.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inclassfeb2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
